{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d80341db7baace5045a5826cd783d0f",
     "grade": false,
     "grade_id": "cell-0b5b35a96a71be61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if your change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "442b24fad7b1ec9e60cc91bef0989733",
     "grade": false,
     "grade_id": "cell-394c67dc171e7069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### WARNING\n",
    "Please refrain from using **print statements/anything that dumps large outputs(>1000 lines) to STDOUT** to avoid running to into **memory issues**. \n",
    "Doing so requires your entire lab to be reset which may also result in loss of progress and you will be required to reach out to Coursera for assistance with this.\n",
    "This process usually takes time causing delays to your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce8df33450ff36ea8f60a0dc08b7c917",
     "grade": false,
     "grade_id": "cell-2269ea6b4acb7d83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 1. Data cleaning and Exploratory Data Analysis (EDA)\n",
    "\n",
    "This part will practice data cleaning and Exploratory Data Analysis (EDA) using a house price dataset and mpg dataset.<br>\n",
    "The first dataset is from a Kaggle competition (https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview), where the task is to predict a house sale price given house features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aac7720d21bf941850510343471e6a1b",
     "grade": false,
     "grade_id": "cell-7bcce53519ddd6fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "224c88fe3018f402a9d0fc9e1f6aa9f1",
     "grade": false,
     "grade_id": "cell-be296cfc3517ca28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9d0cea4e9d8310e45416055f34ed591",
     "grade": false,
     "grade_id": "cell-7714e2bdf5952e3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Import data and visually inspect the table [9 pts]\n",
    "### 1a) Data import and basic inspection. [5 pts]\n",
    "We can import the csv data using `pd.read_csv()` function. We can use `df.head()` and `df.tail()` to show the first and last 5 entries. `df.iloc[[3,5,7]]` shows the entries corresponding to the index 3,5,7. \n",
    "What is the maximum value of the feature `MSSubClass` among the last 10 entries? Update the value of `maxval` to the correct integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a865611cb735d837742bea8d6b77e2e",
     "grade": false,
     "grade_id": "cell-cb3fee7b585bdbbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/house_data.csv') #it is the same data as the kaggle competition's train.csv.\n",
    "# your code here\n",
    "\n",
    "# uncomment maxval and update the correct integer value\n",
    "# maxval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9976c00475926306b5361b0524b23b6d",
     "grade": true,
     "grade_id": "cell-db1c05d10186bbee",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell tests that you correctly updated maxval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6e178199083d40592178dc1e07f4876",
     "grade": false,
     "grade_id": "cell-cbb2410b4001a470",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1b) df.info() gives the overview of the data frame. Inspect the data using df.info() and answer below questions. [4 pts]\n",
    "#### 1b-i) Which column is the target? \n",
    "#### 1b-ii) How many features are in the data? Exclude the target. (Id is not a useful feature, but let's still include)\n",
    "#### 1b-iii) How many observations (samples) are in the data? \n",
    "#### 1b-iv) How many features have null values based on the data overview?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c144b53d50664eaefbe6f0196317006",
     "grade": false,
     "grade_id": "cell-3522093cb3440da0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# uncomment and update to the correct string value\n",
    "# copy directly from the uneditd df column name (e.g., 'LandContour')\n",
    "# ANS_1b1 = '' \n",
    "# uncomment and update to the correct integer value\n",
    "# ANS_1b2 = 0 \n",
    "# uncomment and update to the correct integer value\n",
    "# ANS_1b3 = 0 \n",
    "# uncomment and update to the correct integer value \n",
    "# ANS_1b4 = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a87e88b6f3ad3d7377dc01dd9c41d81b",
     "grade": true,
     "grade_id": "cell-7ac0bd360d9fc2a7",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell will test your solutions to the four questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c2b43a20aecebec94d793423f67d7a0",
     "grade": false,
     "grade_id": "cell-2c74538cd1d26fde",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Inspect Null values [16 pts]\n",
    "The empty values in the data are called null values. Null values can take different forms.\n",
    "Have a look at below example. `np.nan` and `None` are native null values in python. They get displayed differently in the pandas dataframe (`pd.DataFrame`) though. But there are other data types such as empty list, empty dictionary, etc and string values that literally says \"null\" or that are empty spaces.\n",
    "Depending on how messy the data is, sometimes the table may have null values of one or more kinds, and those can be cleaned manually or automatically if you can write a code to include all possible cases which meanings are null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37a978e00423711d669cd22162d8945d",
     "grade": false,
     "grade_id": "cell-fd7633f1ff343c36",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "a = [np.nan, None, [], {}, 'NaN', 'Null','NULL','None','NA','?','-', '.','', ' ', '   ']\n",
    "nulldemo = pd.DataFrame(a)\n",
    "nulldemo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e3fa8647e5bf3ac72ae4f5664a50955",
     "grade": false,
     "grade_id": "cell-4aaf5e4be60651bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "`.isnull()` method applied to pandas dataframe or series can detect null values. `.dropna()` method in pandas will detect null values and can be specified to drop either rows or columns that contain null values. Below shows that `.isnull()` only detects the python-native null values and cannot detect other forms (string value) of variables that meant null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "500eaa2e262bba4c183501354ee38232",
     "grade": false,
     "grade_id": "cell-55ce28863f9058c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "nulldemo.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8208f611fd1787ad8966ef5c0f9fcaa",
     "grade": false,
     "grade_id": "cell-7b3e462ec41ac482",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Also, sometimes the python-native null values can have an odd data type such as numpy float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d5b4a35a64c4ef0213c130ef2bff6a5",
     "grade": false,
     "grade_id": "cell-c2d9834dfe085a8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print(df['MasVnrArea'].iloc[234], df['MasVnrArea'].iloc[234].dtype, type(df['MasVnrArea'].iloc[234]))\n",
    "print(df['MasVnrArea'].isnull().iloc[234])\n",
    "print(np.isnan(df['MasVnrArea'].iloc[234])) \n",
    "print(math.isnan(df['MasVnrArea'].iloc[234]))\n",
    "print(df['MasVnrArea'].iloc[234]==np.nan)\n",
    "print(df['MasVnrArea'].iloc[234]==np.float64(np.nan))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4551c525ba615d3ba7708b262efd8f84",
     "grade": false,
     "grade_id": "cell-8f2e347fb71d0786",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "np.isnan() and math.isnan() can detect the nan values with numpy float type, but they will cause errors with native `None` or a string value. Uncomment one of below (one at a time) and run. You'll see error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5de92f8d9e6de1f77655c03ab01fa212",
     "grade": false,
     "grade_id": "cell-f667da7b22e3108f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# print(np.isnan(None))\n",
    "# print(np.isnan('None'))\n",
    "# print(math.isnan(None))\n",
    "# print(math.isnan('None'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "18303930f8985b16e35d5dea35b09ed0",
     "grade": false,
     "grade_id": "cell-3ef55c38761403b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2a) Check null values type [5 pts]\n",
    "Let's check if our data has clean null values (one kind) or messy null values (multiple different representations). Run the codes below and visually inspect the printed results. Which column has string-typed null/none values and how many elements are string-typed null/none values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0e3ae50ea98f5c4f99dece0bae5bd21",
     "grade": false,
     "grade_id": "cell-a40d26bd98654b9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# prints number of null values detected by .isnull() and string none\n",
    "for c in df.columns:\n",
    "    string_null = np.array([x in a[2:] for x in df[c]])\n",
    "    print(c, df[c].isnull().sum(), string_null.sum()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e2d7f06320fd6252cea08b30c289104",
     "grade": false,
     "grade_id": "cell-d07930006ff0e3a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which column has string-typed null/none values? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b5e24f7f6ddcada46ac3ddfa0eebdb1",
     "grade": false,
     "grade_id": "cell-584c0338abbd45f8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update to the correct string value\n",
    "# col = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "97d0d0af16dbe7cf5fed18936f349965",
     "grade": false,
     "grade_id": "cell-fa00937941485363",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "How many elements are string-typed null/none values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37741cd100f1c8831f078c1308d56b42",
     "grade": false,
     "grade_id": "cell-a53c8dc23ac393d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update to the correct string value\n",
    "# string_null_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9866646b79d79c952b8dca25f05f2add",
     "grade": true,
     "grade_id": "cell-dce6d5bd3d2c3fa5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell will test your answer about the column with string-typed null/none values\n",
    "# and the number of string-typed null/none values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5a2126c265abee059ef01af2e883bcff",
     "grade": false,
     "grade_id": "cell-42f5ae89bca3b8ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2b) Inspect observations (rows) with null values. How many observations have at least one missing value? [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c929bf86ad7b3e2e6fd5b2a09565153",
     "grade": false,
     "grade_id": "cell-583168388460d97e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update to the correct integer value\n",
    "# rows_with_nulls = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5dfe677f9d2e75aaf2cfb395290c552c",
     "grade": true,
     "grade_id": "cell-5e23e1b0cca76fd6",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this cell will test your answer about the number of rows with null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "11e69f21895b746ac14afcbbd1d46cc1",
     "grade": false,
     "grade_id": "cell-77d2e86ca5e292b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2c) Make a histogram of null counts [6 pts]\n",
    "+ The ***histogram x-axis*** is the null value count range. Please use bins with width = 50 (e.g. bins are [0,50,100, ...,1550])\n",
    "+ The ***histogram y-axis*** is the count of features with the number of null values within the histogram bin range. For example, if 10 feature columns have numbers of null values between 0 and 50, then the first box's y-value is 10 in the plot. <br>\n",
    "\n",
    "**Hint**: matplotlib library has a function .hist that can plot histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "876cde624bae4f290fe7eb2dbb558e5b",
     "grade": false,
     "grade_id": "cell-397bc70fa5b6e142",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# Hint: Use .isnull() and sum over True values on columns.\n",
    "# You can make it as short as 2-3 lines of code\n",
    "\n",
    "# Hint: Obtain null_counts of features and ONLY retain features that have atleast 1 null count i.e features with \n",
    "# zero null count should not be included in the list. \n",
    "\n",
    "# Please uncomment and update\n",
    "# do not change the names of the variables from null_counts and histogram\n",
    "\n",
    "# null_counts=pd.Series([])\n",
    "# histogram = None # replace the histogram to be the plt.hist() object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1c21302cd3c9470a1764307c1403941f",
     "grade": true,
     "grade_id": "cell-09022e4fedc38031",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test; basic histogram tests\n",
    "assert(len(histogram[0])==30), \"Check null_counts, make sure features with zero null values are not included\"\n",
    "assert(len(histogram[1])==31), \"X-axis is null value count range [0...1500], bin width 50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d37296bfc5a5b719cde94bffb0700843",
     "grade": true,
     "grade_id": "cell-1227cde34a107169",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test 1; tests null_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a80f7b0a9192570523ae623a71382665",
     "grade": true,
     "grade_id": "cell-47db4d8d4a9b3d99",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden test 2; tests histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "88f23f4ed8278234ef6be3b83373c6b8",
     "grade": false,
     "grade_id": "cell-f79e729452eb49a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Imputing missing values [33 pts]\n",
    "\n",
    "In this part, we will decide methods to clean the data with missing values.    \n",
    "\n",
    "Complete case analysis (CCA) is to drop any observations (rows) that have null values. It is suitable if the number of observations with null values are very small (say, less than 5%) compared to the total number of observations.  \n",
    "\n",
    "If the data has a large number of features (columns) and the model(s) does not need that many features (some models work better with less number of features), we can consider dropping features that have many missing values. Before dropping features, it is generally a good idea checking whether the feature with missing values is important feature or not (which may need the analyst's judgement). If the feature is very important for the prediction task (for example, a house size when predicting house price) but has a large amount of missing values, we cannot simply drop the feature, or in a rare case, it could mean that the data is not suitable for the analysis. One will have to work with only the observations that has values on that feature given the number of observations is sufficient, or collect more data. If we know that those features are not very important and have a large number of missing values, we can drop the features. As a rule of thumb, features with missing values more than either 5% or 10% can be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83fb2629ca41edfbcaec688790d9374a",
     "grade": false,
     "grade_id": "cell-ff5b47f4fe830116",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3a) Is the data suitable for complete case analysis or not? [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61ad79cc50b7a8d8d76c2527812c07d0",
     "grade": false,
     "grade_id": "cell-9660a54734798c9f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# uncomment and update to string 'no' or 'yes'\n",
    "# suitable_cca = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3fd7736e8eb717094af17a594f91477",
     "grade": true,
     "grade_id": "cell-596e41e829fd93c0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests solution for whether data is suitable for CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f8da413a152c30d8649d8bbd62afc04",
     "grade": false,
     "grade_id": "cell-0e3d217af51ab25a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b) Dropping feature columns [20 pts]\n",
    "**Imputation** is the process of replacing missing data with substituted values. Let's assume we want to keep columns where 5% or less of the values are null (***keep and impute***) and discard any column where more than 5% of the values are null (***throw***). Treat the string type \"None\" as a category and not a null value.\n",
    "\n",
    "#### 3b-i) According to above condition (5% threshold), how many features can be kept and imputed? [5 pts]\n",
    "#### 3b-ii) Which columns have null values 5% or less of total, so we can impute? [5 pts] \n",
    "#### 3b-iii) Which columns have null vaues more than 5% of total, so we should throw? [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "239a1e5b584d12dc44ac19f0505313be",
     "grade": false,
     "grade_id": "cell-372f8f3eaee8295e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# 3b-i Hint: In the previous question 2c we calculated null_counts of all the features. We can split that into 2\n",
    "# lists i.e features_to_impute and features_to_throw. \n",
    "# features_to_impute will contain features/columns that have null values <= 5% of the total number of rows.\n",
    "# features_to_throw will contain features/columns that have null values > 5%\n",
    "\n",
    "# Complete the codes below by uncommenting and changing the values of features_to_impute and features_to_throw. \n",
    "# Each should be a list of feature names (e.g. ['LotFrontage','Alley',...]). Do not change the variable names. \n",
    "# There are hidden tests which will grade above three questions.\n",
    "\n",
    "# features_to_impute = []\n",
    "# features_to_throw = []\n",
    "\n",
    "# print(len(features_to_impute), features_to_impute)\n",
    "# print(len(features_to_throw), features_to_throw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f8462fb0a619a99fd81b8cec7d3f1d0",
     "grade": true,
     "grade_id": "cell-eebd5d9ed1f05b19",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test for 3b-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c0fe0f40b40878be1f837edbbb780c3",
     "grade": true,
     "grade_id": "cell-5f5faeb0cae30c87",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test for 3b-ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18c4c925861d200220fa5a5a317ae705",
     "grade": true,
     "grade_id": "cell-ab80387b81834de8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden test for 3b-iii"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b48a52c1e196737872077ecce6d9d6fb",
     "grade": false,
     "grade_id": "cell-711815474f799b5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3b-iv) Remove the columns according to the above result. Replace the `df` with the new result. Also remove `Id` column as it's not a useful feature. [5 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4151579b7d29b2a96a35370e384c6c04",
     "grade": false,
     "grade_id": "cell-5c687ea4a0ba9db5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# remove the columns according to the above result, replace df with the new results\n",
    "# also remove ID column as it's not a useful feature\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e88a950221bbf615924d9d352795635d",
     "grade": true,
     "grade_id": "cell-f6c0fb38ec21da14",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that you properly updated df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51676bcf1ccf98b495f97acf8b653866",
     "grade": false,
     "grade_id": "cell-d4cebd6f858b3f50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3c) Impute missing data [8 pts]\n",
    "Before imputing columns, we need to think about what methods to use to impute columns.\n",
    "The imputation strategy can be different depending on the variable types and variable value distribution. There are many imputation techniques, but let's use a few simple ones.    \n",
    "\n",
    "For a numerical variable imputation, we impute mean value if the distribution is symmetric while we use median value to impute when the distribution is skewed. Another method is to assign an arbitrary value that's outside the normal range. Though it can be useful to capture missingness, but it can create outliers. Both mean/median and arbitrary imputation methods are simple to use and suitable when missing values are 5% (no more than 10%) as a rule of thumb. Both methods can distort the original distribution.\n",
    "\n",
    "For a categorical variable imputation, we can impute with the most frequent categorical value. It is a simple method but it can distort the original distribution. \n",
    "It is also possible to create a \"missing\" category to capture missingness. The advantage of using missing category is that it captures missingness but its disadvantage is that it creates another rare category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "860532c99a2364873a696d00826062a0",
     "grade": false,
     "grade_id": "cell-1682d3325bf66ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below code shows histograms of feature columns that we can impute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c56df78836335b4d8586514930f46da2",
     "grade": false,
     "grade_id": "cell-09e44205ad080ceb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for c in features_to_impute:\n",
    "    df[c].hist()\n",
    "    plt.title(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ecaaecf44eb0d6152328b826d3952a8d",
     "grade": false,
     "grade_id": "cell-45e51c905bfb2740",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3c-i) Impute missing data for features in `features_to_impute`. Choose an appropriate method among mean or median imputation methods for numerical variable(s) and frequentest value imputation for categorical variable(s). [8 pts]\n",
    "You can inspect variable types by eyes, or use below code as a help. Replace those columns with imputed values. Do not change the column name or the data frame name. Do not add new columns to the data frame.     \n",
    "Hint: You can use .mode() function to find the most frequent value in a Series.    \n",
    "Hint: You may use .fillna() function on each feature Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e19ffc8484ab7f7624020f1b8b79fc6",
     "grade": false,
     "grade_id": "cell-eb5b21da40da7855",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for c in features_to_impute:\n",
    "    print(c, len(df[c].unique()), df[c].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9b2ba0b60d1e6b0c63f4b913f023d402",
     "grade": false,
     "grade_id": "cell-683379e1f19a7fcd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# use this cell for potential debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13775d500b53bea742ca777c207f4f77",
     "grade": false,
     "grade_id": "cell-8bc59664c30aac38",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# impute missing data \n",
    "# your code here\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b2588655fb1d2190b231dc475d66d8c",
     "grade": true,
     "grade_id": "cell-a2efc78ce51e841f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Sample Tests features_to_impute\n",
    "for c in features_to_impute:\n",
    "    assert df[c].isnull().sum()==0, f\"Feature: '{c}' still has null values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "876fd25dabc127165dc3c0d6f2625591",
     "grade": true,
     "grade_id": "cell-42e7620ebac48500",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests 'MasVnrType' and 'MasVnrArea'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7dfd5e040d035d2b94d6534bb8f1c530",
     "grade": true,
     "grade_id": "cell-56558f302e7a8c4c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tsts 'BsmtQual' and 'BsmtCond'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07934d185f4c9f125821c8c0cb1f6e5a",
     "grade": true,
     "grade_id": "cell-371f8ca891ba7f38",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests 'BsmtExposure' and 'BsmtFinType1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12dad82c142865569403ac4d9e89e5bd",
     "grade": true,
     "grade_id": "cell-7153efa6632bcbf9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests 'BsmtFinType2' and 'Electrical'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bfb7024f724583aa745c4ef0d2327d7c",
     "grade": false,
     "grade_id": "cell-3a0e60201d41e0cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part 2. EDA, Simple Linear Regression\n",
    "\n",
    "In this part, we will use a simplified data and create a simple linear regression model. The dataset can be downloaded from https://www.kaggle.com/harlfoxem/housesalesprediction/download.    \n",
    "This dataset contains house sale prices for Kings County, which includes Seattle. It includes homes sold between May 2014 and May 2015. There are several versions of the data. Some additional information about the columns is available here: https://geodacenter.github.io/data-and-lab/KingCounty-HouseSales2015/, some of which are copied below.\n",
    "\n",
    "|Variable |\tDescription|\n",
    "|:---------|:-------------|\n",
    "|id \t|Identification|\n",
    "|date |\tDate sold|\n",
    "|price |\tSale price|\n",
    "|bedrooms |\tNumber of bedrooms|\n",
    "|bathrooms |\tNumber of bathrooms|\n",
    "|sqft_liv |\tSize of living area in square feet|\n",
    "|sqft_lot| \tSize of the lot in square feet|\n",
    "|floors |\tNumber of floors|\n",
    "|waterfront |\tâ€˜1â€™ if the property has a waterfront, â€˜0â€™ if not.|\n",
    "|view |\tAn index from 0 to 4 of how good the view of the property was|\n",
    "|condition |\tCondition of the house, ranked from 1 to 5|\n",
    "|grade |\tClassification by construction quality which refers to the types of materials used and the quality of workmanship. Buildings of better quality (higher grade) cost more to build per unit of measure and command higher value.|\n",
    "|sqft_above |\tSquare feet above ground|\n",
    "|sqft_basmt |\tSquare feet below ground|\n",
    "|yr_built \t|Year built|\n",
    "|yr_renov |\tYear renovated. â€˜0â€™ if never renovated|\n",
    "|zipcode |\t5 digit zip code|\n",
    "|lat \t|Latitude|\n",
    "|long \t|Longitude|\n",
    "|squft_liv15 |\tAverage size of interior housing living space for the closest 15 houses, in square feet|\n",
    "|squft_lot15 |\tAverage size of land lost for the closest 15 houses, in square feet|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "618f5da678b36c8a3182068e76b17c60",
     "grade": false,
     "grade_id": "cell-4164737ecf84807d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import copy\n",
    "# Set color map to have light blue background\n",
    "sns.set()\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dd7592ae08aaed6c228f393142093e8",
     "grade": false,
     "grade_id": "cell-ab53fad4700fc069",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data/house_data_washington.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8502892af75a810bf19acd19416ab1b4",
     "grade": false,
     "grade_id": "cell-b9c982194d2d0f40",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. Munging data [15 pts]\n",
    "### 4a) Date string to numbers [5 pts]\n",
    "Inspect the data frame and data type of each column. The column 'date' is the date sold, and has string value. We will extract year and month information from the string. \n",
    "In the data frame df2, create new features 'sales_year' and 'sales_month'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7be2a3c59fd8b06ed34c697728ae78d9",
     "grade": false,
     "grade_id": "cell-def60c6a987f3af9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# extract year and month info from the string\n",
    "# create new features 'sales_year' and 'sales_month' in df2\n",
    "df2['sales_year'] = df2.date.apply(lambda x: int(x[:4]))\n",
    "df2['sales_month'] = df2.date.apply(lambda x: int(x[4:6]))\n",
    "print(df2.groupby('sales_month')['id'].count())\n",
    "print(df2.groupby('sales_year')['id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e26b3968479f7401a22b2b5f7904e32",
     "grade": false,
     "grade_id": "cell-270ddcab2bd221ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which month has the most number of sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "530f916f96704d41addaeefd27e5d874",
     "grade": false,
     "grade_id": "cell-447e548e063eb680",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update string with capitalized month, e.g., 'December'\n",
    "# most_sales = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f30c322e9d2b1fecfcf52e6ca837a5f7",
     "grade": false,
     "grade_id": "cell-ab45a9249c1c8285",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Which months has the least number of sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a956c0433e5d69ab8f8dc816fa0a2fa8",
     "grade": false,
     "grade_id": "cell-05ff2ec904565f4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update string with capitalized month, e.g., 'December'\n",
    "# least_sales = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5a73a6bbf29823865efc3d9ae946188",
     "grade": true,
     "grade_id": "cell-cadc8a85fd0b5630",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests solutions for most_sales and least_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0e95641a080905b17db379d46d18068",
     "grade": false,
     "grade_id": "cell-830d3bb5de332b12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6fe4a4479b2bcbf792324283a0f2df4b",
     "grade": false,
     "grade_id": "cell-6107c495a67fc96b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4b) Variable types [5 pts]\n",
    "Inspect each feature's data type and variable type. What is the best description for the variable type of following features? Update the string to 'numeric' or 'categorical'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aa66075bc13defaa2f776454df018e58",
     "grade": false,
     "grade_id": "cell-d1457a08b8feb7e4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "\n",
    "# uncomment the feaures below and update the strings with 'numeric' or 'categorical'\n",
    "# price = ''\n",
    "# bathrooms = ''\n",
    "# waterfront = ''\n",
    "# grade = ''\n",
    "# zipcode = ''\n",
    "# sales_year = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d53b61461c0ea71620a5ca3ebb824cd6",
     "grade": true,
     "grade_id": "cell-83405385a8bf3251",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that you selected correct variable type for the features in 4b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad79a39988e7225145617fbd053757bb",
     "grade": false,
     "grade_id": "cell-907eb0b299367ce9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# this part is ungraded, but useful to run to check\n",
    "# your code here\n",
    "\n",
    "for c in df2.columns[2:]:\n",
    "    print(c, df2[c].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7d6258d4287df3aca3ec49586c01f17",
     "grade": false,
     "grade_id": "cell-ee0110eb32b0b7ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4c) Drop features [5 pts]\n",
    "Let's drop features that are unnecessary. `id` is not a meaningful feature. `date` string has been coded to `sales_month` and `sales_year`, so we can remove `date`. `zipcode` can be also removed as it's hard to include in a linear regressio model and the location info is included in the `lat` and `long`.\n",
    "Drop the features `id`, `date`, and `zipcode` and replace the df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1cbf99fee58b9ce3909532cc4bfe9ed8",
     "grade": false,
     "grade_id": "cell-fba7fcd19732194e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# drop unnecessary features, replace df2\n",
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "168f22892a862f746c7b8f6d4e9b940b",
     "grade": true,
     "grade_id": "cell-09acbfd67a77b038",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests that you droppd the features id, date, and zipcode from df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1c45f66c50ac14cfb30250dc8993dfa",
     "grade": false,
     "grade_id": "cell-c28ed0de4ca75d60",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5. More inspection; Correlation and pair plot [5 pts and Peer Review]\n",
    "### 5a) Get correlation matrix on the data frame. [5 pts]\n",
    "Which feature may be the best predictor of price based on the correlation? Answer as a string value (e.g. best_guess_predictor = 'price' or best_guess_predictor = 'yr_built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb690bf4d70356a08f0ee1f6d5e1545d",
     "grade": false,
     "grade_id": "cell-0e9bdc9ee6161b7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update best_guess_predictor with a string value\n",
    "# best_guess_predictor = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cab8b0ff1b82e974b4cf97ca749a863b",
     "grade": true,
     "grade_id": "cell-455e59f31501b283",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests the solution for best_guess_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1817d93250c95bb59947131cfa2a46dd",
     "grade": false,
     "grade_id": "cell-7120f691348f8907",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5b) Display the correlation matrix as heat map [Peer Review]\n",
    "[`seaborn.heatmap()`](https://seaborn.pydata.org/generated/seaborn.heatmap.html) can visualize a matrix as a heatmap. Visualize the correlation matrix using seaborn.heatmap(). Play with color map, text font size, decimals, text orientation etc. If you find how to make a pretty visualization, please share in the discussion board. You will upload your correlation matrix in the Peer Review assigment for the week. <br>\n",
    "**Note:** your code for this section may cause the Validate button to time out. If you want to run the Validate button prior to submitting, you could comment out the code in this section after completing the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e95f16cad0f32b2a0c93718527f1e245",
     "grade": false,
     "grade_id": "cell-2e19c30b0454fabd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# practice visualizing correlation matrix using a heatmap\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bc30478e1041f69ef668e8b3c49d34c",
     "grade": false,
     "grade_id": "cell-b376b65ab6badfa0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5c) Pair plot [Peer Review]\n",
    "Pair plot is a fast way to inspect relationships between features. Use seaborn's .pairplot() function to draw a pairplot if the first 10 columns (including price) and inspect their relationships. Set the diagonal elements to be KDE plot. You will upload your pair plot in this week's Peer Review assignment. <br>\n",
    "**Note:** your code for this section may cause the Validate button to time out. If you want to run the Validate button prior to submitting, you could comment out the code in this section after completing the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db9c2c0cb30348e3839528115fd1cac4",
     "grade": false,
     "grade_id": "cell-630895ed926e33b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# practice inspecting relationships between features using a pair plot. \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17d88751d4b6c6ce5a179f59ead2b6a1",
     "grade": false,
     "grade_id": "cell-a472da53d90eea44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 6. Simple linear regression [Peer Review]\n",
    "\n",
    "### 6a) Data preparation [Peer Review]\n",
    "We will split the data to train and test datasets such that the test dataset is 20% of original data.\n",
    "Use `sklearn.model_selection.train_test_split` function to split the data frame to X_train and X_test. X_train is 80% of observation randomly chosen. X_test is the rest 20%. Both X_train and X_test are `pd.DataFrame` object and include 'price' in the table. Note that the train_test_split can handle data frame as well as array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e9fcdf30cfa8d2d20762ef012c40469",
     "grade": false,
     "grade_id": "cell-039f3a4314195737",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# use sklearn.model_selecttion.train_test_split to split the data frame \n",
    "# X_train is 80% of the observations; X_test is 20% of the observations\n",
    "# print length of X_train and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7879f6fd73e15916025a54f47ea855f9",
     "grade": true,
     "grade_id": "cell-8e12fbb95b41c1fd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Testing cell \n",
    "assert(len(X_train) == 17290), \"Check 6a, did you split properly so X_Train is 80% of the observations?\"\n",
    "assert(len(X_test) == 4323), \"Check 6a, did you split properly so X_test is 20% of the observations?\"\n",
    "assert(type(X_train)==type(pd.DataFrame())), \"Check 6a, what type of object should X_train be?\"\n",
    "assert(type(X_test)==type(pd.DataFrame())), \"Check 6a, what type of object should X_test be?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a6b954af67ca126c9ab32f0ee4dbd36d",
     "grade": false,
     "grade_id": "cell-d4c22fe96e318333",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6b) Train a simple linear regression model [Peer Review]\n",
    "Use the best_guess_predictor as a single predictor and build a simple linear regression model using **`statsmodels.formula.api.ols`** function (https://www.statsmodels.org/dev/example_formulas.html)\n",
    "Print out the result summary. Train on the X_train portion. What is the adjusted R-squared value?\n",
    "\n",
    "N.B.: It recommended that you use the statsmodel library to do the regression analysis as opposed to e.g. sklearn. The sklearn library is great for advanced topics, but it's easier to get lost in a sea of details and it's not needed for these problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1aa5d5175fb75ab05a996dd6885ba3b",
     "grade": false,
     "grade_id": "cell-f5291d1c1d6ebee5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use best_guess_predictor as a single predictor\n",
    "# build a simple linear regression model, train on the X_train portion\n",
    "\n",
    "# Make sure to use the `statsmodels.formula.api.ols` function for building the model. \n",
    "# your code here\n",
    "\n",
    "# model = \n",
    "adj_R2 = None #update this value according to the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3160d14ebef2700538db6f5b9a62867f",
     "grade": false,
     "grade_id": "cell-a69012fe381b2827",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 6c) Best predictor [Peer Review]\n",
    "In question 5a, we picked a best guess predictor for price based on the correlation matrix. Now we will consider whether the best_guess_predictor that we used is still the best.<br>\n",
    "Print out a list ranking all of the predictors. Then print out a list of the top three predictors in order.<br>      \n",
    "Hint: Linear regression uses adjusted R squared as fit performance. <br>\n",
    "In this week's Peer Review, answer the following questions: What were your top three predictors? How did you order your list of predictors to select those as the top ones? Is your top predictor for this section the same as the best guess predictor you selected in question 5a? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "19eb58f3f171dc9a81cac6256d8ec962",
     "grade": false,
     "grade_id": "cell-9ca80c1b78b9ccd7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# uncomment and update top_three\n",
    "# top_three = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac8c6bcc83c1bd77bba7c986149cc02d",
     "grade": false,
     "grade_id": "cell-a1c9231f7c678cca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# instructor testing cell \n",
    "# your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
