{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Disaster Tweets Kaggle Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Description\n",
    "\n",
    "The task in this competition is to develop a machine learning model that predicts whether a given tweet is related to a real disaster or not. Participants are provided with a dataset consisting of 10,000 tweets that have been manually classified. The primary goal is to use this data to train and evaluate models that can accurately classify tweets into disaster-related or not disaster-related categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import re\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('dark')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "\n",
    "#sets the default autosave frequency in seconds\n",
    "%autosave 60\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows',100)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: (7613, 5)\n",
      "Test set size: (3263, 4)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check the sizes of train and test sets\n",
    "print(\"Train set size:\", train_data.shape)\n",
    "print(\"Test set size:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set preview:\n",
      "   id keyword location                                               text  target\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...       1\n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada       1\n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...       1\n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...       1\n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...       1\n",
      "\n",
      "Test set preview:\n",
      "   id keyword location                                               text\n",
      "0   0     NaN      NaN                 Just happened a terrible car crash\n",
      "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
      "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
      "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
      "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Preview the first few rows of the datasets\n",
    "print(\"\\nTrain set preview:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTest set preview:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set statistics:\n",
      "             id     keyword location                                               text  target\n",
      "count   7613.00        7552     5080                                               7613 7613.00\n",
      "unique      NaN         221     3341                                               7503     NaN\n",
      "top         NaN  fatalities      USA  11-Year-Old Boy Charged With Manslaughter of T...     NaN\n",
      "freq        NaN          45      104                                                 10     NaN\n",
      "mean    5441.93         NaN      NaN                                                NaN    0.43\n",
      "std     3137.12         NaN      NaN                                                NaN    0.50\n",
      "min        1.00         NaN      NaN                                                NaN    0.00\n",
      "25%     2734.00         NaN      NaN                                                NaN    0.00\n",
      "50%     5408.00         NaN      NaN                                                NaN    0.00\n",
      "75%     8146.00         NaN      NaN                                                NaN    1.00\n",
      "max    10873.00         NaN      NaN                                                NaN    1.00\n",
      "\n",
      "Test set statistics:\n",
      "             id  keyword  location                                               text\n",
      "count   3263.00     3237      2158                                               3263\n",
      "unique      NaN      221      1602                                               3243\n",
      "top         NaN  deluged  New York  11-Year-Old Boy Charged With Manslaughter of T...\n",
      "freq        NaN       23        38                                                  3\n",
      "mean    5427.15      NaN       NaN                                                NaN\n",
      "std     3146.43      NaN       NaN                                                NaN\n",
      "min        0.00      NaN       NaN                                                NaN\n",
      "25%     2683.00      NaN       NaN                                                NaN\n",
      "50%     5500.00      NaN       NaN                                                NaN\n",
      "75%     8176.00      NaN       NaN                                                NaN\n",
      "max    10875.00      NaN       NaN                                                NaN\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Generate basic statistics for the datasets\n",
    "print(\"\\nTrain set statistics:\")\n",
    "print(train_data.describe(include='all'))\n",
    "\n",
    "print(\"\\nTest set statistics:\")\n",
    "print(test_data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in train set:\n",
      "id             0\n",
      "keyword       61\n",
      "location    2533\n",
      "text           0\n",
      "target         0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test set:\n",
      "id             0\n",
      "keyword       26\n",
      "location    1105\n",
      "text           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Check for missing values\n",
    "print(\"\\nMissing values in train set:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in test set:\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAGUCAYAAAD9McJvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+SUlEQVR4nO3deVwVZf//8fcBQWVTqVxyJQ0sRUUQMxAz18zcuus2d8qolEwzbbnvbFdvLDfEwlLTr9ri7fazRUNLlCzFFitNywVRKjOQDhwkhTO/P/xyvh4PKiAIk6/n49Ejuc5nZq4ZzsCba66ZYzEMwxAAAIBJuFV2BwAAAEqD8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8AIAAEyF8IKrSnx8vIKCgpz+a9mypdq1a6eePXtqypQpOnz4sMtyx44dU1BQkMaMGVOm7e7Zs0eff/55qfq4adOmctn2pXzxxRf6/vvvHV/v2LFDQUFBeuWVVypke+UtMzNTY8eOVWhoqNq1a6fnnnvOpaZon0r637FjxyphT0rujz/+0Jo1ay5ak5iYqKCgIE2dOvWS64uNjVVQUJC++uqrcunf8OHDFRQUJKvVWuplS/P+q+hzA1VXtcruAFAZunXrpptuukmSZLfblZubq59++knvv/++1q1bpzlz5ui2225z1Pv5+Sk2NlY33HBDqbeVnJyshx9+WE8++aQiIiIuWR8eHq7Y2FgFBASUelul9e677+q5555TQkKCgoODJUkNGzZUbGys2rZtW+HbLw+vvPKKNm3apI4dO6pt27bF9rton861c+dO7dy50+m9UMTPz69C+3w5MjMz1bt3b4WHh2vgwIEXrOvfv79mz56tDRs26Omnn5bFYim2LicnR8nJyWrSpIlCQ0PLpY8DBw5UeHi4qlevXi7rA85HeMFVqXv37ho0aJBL+7Zt2zRmzBhNmDBBa9euVdOmTSWd/WX26KOPlmlbmZmZstvtJa7v2LGjOnbsWKZtldaJEydc2ho1alTmfa0Me/bskbu7u958880L/rIsbp/i4+O1c+fOC74XqqpTp04pJyfnknX169dXx44d9cUXX+irr75SWFhYsXUbNmzQ6dOnNWDAgHLro5mOJ8yJy0bAOTp37qzx48crLy9P8+fPr+zuoATOnDkjLy8v/sovRlEg+fDDDy9Ys379elkslnINL0BFI7wA5xk6dKhq1KihTz75RGfOnJFU/LX1M2fOKD4+XnfddZfatm2r8PBwPfDAA05zW5566ik9/fTTkqRp06Y55lMUXddfvny5xo0bp+DgYEVGRuqrr75ymfNyro0bN+quu+5ScHCwevXqpcTEREcfiwQFBal///4uy65evVpBQUF6++23JZ2dlzBv3jxJ0tixYxUUFCTpwnMODhw4oAkTJqhTp05q3bq1evXqpdmzZysvL8+pbvjw4br99tv122+/aeLEiY7LOUOHDtWOHTtK9D2QpHXr1unee+9V27ZtFRISoqFDh2rz5s0u+5ORkaGcnBzHfJXykJWVpf/85z+64447HJei7rzzTs2fP18FBQUuffjoo480YsQItW7dWl27dtXRo0clSenp6Xr88cd16623KiQkRA8++KAOHjyoHj16aPjw4U7bPH36tBITE9WnTx8FBwerU6dOmjhxomNdRdvr1q2bJGnz5s0KCgrS6tWrL7gfPXv2lJeXlzZu3KjCwkKX148fP67U1FSFh4erYcOGks6+16dMmaLu3bsrODhYISEhGjRokJYvX+60bNH79PPPP9egQYMc7wmbzVbsnBebzaZ58+apf//+CgkJUXBwsHr27Kn//Oc/stlsxfZ/xYoV6tGjh4KDg3XXXXfp3XffveC+lvZYwtwIL8B5atSooZtuukl5eXn68ccfL1j34osvat68eapdu7aGDRum3r17a/fu3Ro9erS++OILSWcvTxX9somMjFRsbKzTfIqEhATt27dPw4cP10033aSbb775gtv79ttvNX78eDVu3Fj33XefLBaLZs6cqcmTJ5dpP4vmJUhSnz59XOaEnGvXrl26++67tXHjRoWGhmrIkCHy9vbW66+/rmHDhrkEGJvNpiFDhmjfvn0aMGCAunfvrq+//loPPPBAiX6BvPTSS5o8ebJ+/fVX9e/fX3fccYcOHjyoMWPGKDExUZJ00003KTY2Vr6+vvL09FRsbOxF96GkcnJydO+992rp0qVq0aKFRowYob59++rEiROaM2eOZsyY4bLMyy+/rJycHI0YMULBwcFq3Lix0tLS9M9//lMff/yx2rdvr8GDB+vo0aMaMmSIsrOznZY/c+aMHnzwQc2cOVO+vr4aNmyYoqKilJSUpH/84x/66aefHPs8YsQISVJAQIBiY2Nd5uucy8vLSz179lRmZqZ27tzp8voHH3wgu93uuMxz7Ngx3X333Vq3bp3atWunUaNGqUePHjp48KBefPFFLV261GUdkyZNkre3t4YPH67w8HB5e3u71BQUFCg6Olrz5s3TddddpyFDhujuu+9Wfn6+Fi1apCeffNJlmY8//lgvv/yy2rZtq3vvvVc5OTl67rnn9Oqrr15wf0tzLGFyBnAVmTt3rhEYGGisWrXqonXjxo0zAgMDjU2bNhmGYRhHjx41AgMDjUceecQwDMOwWq1Gy5YtjaFDhzot99133xmBgYHGo48+6mhbtWqVERgYaCxevNjR9uWXXxqBgYFG27Ztjd9//73YPiYlJTltOzAw0FiyZImj7tSpU8aIESOMwMBAIyUlxdEeGBho9OvXz2WfiuvH+ds6t28vv/yyYRiGcebMGaN79+5Gq1atjM8//9xRV1hYaDz33HNGYGCgMW3aNEf7sGHDHMfq9OnTjvbXX3/dCAwMNGbPnu3St3MVbX/gwIFGVlaWo/23334zunXrZrRs2dL48ccfHe1du3Y1QkNDL7rO4lzovZCYmGgEBgYa7733nlP7r7/+agQHBxsRERGOtqJjGhUVZeTl5TnVP/jgg0ZgYKDx4YcfOtr++usv47777jMCAwONYcOGOdrffPNNIzAw0Hjttdec1vHDDz8YrVq1Mv7xj3842s5/L17K9u3bjcDAQONf//qXy2v9+/c32rVrZ9hsNsMwDOPZZ591eT8Zxv+9r++9915HW9HxGzRokFFYWOhUX/Qe+PPPPw3DMIwPPvjACAwMNGbOnOlUl5OTY0RERBg33XST4/gVff/PPf8MwzCysrKMvn37Gi1btjQOHjx4wWNRmmMJ82LkBSiGp6enJF1wOFuSDMPQL7/8ol9++cXRFhwcrE2bNum1114r0Xbat2+v6667rkS1TZo00dChQx1f16hRQxMnTpR0dt5CRfnmm2+Unp6uvn376tZbb3W0u7m56YknnlCtWrW0evVqGYbhtNz9998vDw8Px9ddunSRJKWlpV10e2vXrpUkPfnkk6pTp46jvV69eho3bpzsdrtWrVp1mXt1YZGRkXrhhRdc7uSpX7++mjZtqqysLJdloqKiVLNmTcfXWVlZ2rZtm9q3b68+ffo42j09PfXEE0+4LP/f//5Xfn5+GjdunFN7q1at1Lt3b3333Xf6+eefy7Q/HTt2VIMGDZSUlOR0ifHAgQP68ccf1bt3b3l5eUmS+vXrp1deecXlrrjg4GB5e3sXu+89evSQm9vFf5XcfPPNevnllzVy5Eindh8fH7Vu3VqFhYX6888/nV4LDw93jFpKUp06dTRmzBjZ7faLzuGpyGOJqoO7jYBiFIWW4obAJcnX11d33nmnPvjgA/Xo0UMhISGKjIzUbbfdppYtW5Z4O40aNSpxbdu2beXu7u7U1qpVK3l4eGjfvn0lXk9pFa27uNtofXx8FBQUpJ07d+qXX35xzJuQpGbNmrnUSmfnI1zM/v375ebmppCQEJfXivpQkft788036+abb5bNZtPu3buVlpamtLQ0ff/99zp06FCxc0fO/z7u2bNHdrtd7dq1c6lt27atqlX7vx+9NptNhw8f1nXXXafXX3/dpf6PP/6QJP3444+68cYbS70/bm5u6tevnxITE7V9+3ZHiCwKvOdO1A0LC1NYWJiys7P1448/Kj09XYcOHdLu3buVl5en2rVru6y/JO/hgIAABQQE6K+//tLu3bt1+PBhpaWlae/evY55UOcf1/bt27usp+g2+At9/yv6WKLqILwAxcjIyJB08R/M06dPV+vWrbVq1SqlpqYqNTVVs2bN0s0336ypU6dedC5CkdLcIVPcCI27u7uqV6+uU6dOlXg9pZWbmyvp/8LH+erWrStJys/Pd2ovGr0qUvSckfNHaIrbXvXq1V2Wv9i2ytNff/2lmTNn6r333nMc1wYNGig0NFTXXHONjh8/7rLM+d/HkydPSpKuvfZal1p3d3f5+/s7vi46vidOnHBMoC7O+SMTpTFgwAAlJibq448/VpcuXWQYhtavX6+GDRs65j0VbWPatGn64IMPdObMGVksFjVu3Fjh4eHav39/seuuUaPGJbdvt9uVmJioxYsXO/bj2muvVUhIiBo3bqyff/7Z5X1R9L0+V9EfExd6v1+JY4mqgfACnOfPP//UgQMH5OfnpxYtWlywzsPDQ9HR0YqOjtYvv/yizz//XBs2bFBKSooeeughbd682emyyeU6f1JsUVtubq7Lw/OKCwhlDThFvzB+//33Yl8vuqOkuL/Ky7q9omeZ+Pr6Vui2ijN9+nTHXS7Dhg1Tq1atHP3o27dvseHlfEVBr+iX6fnOvRxZdMkmLCzM5Y6e8nLDDTeoTZs22rRpk06fPq3vv/9eGRkZGjt2rNPD6yZNmqTk5GTde++9GjhwoFq2bOno30cffVTm7S9atEizZ89WeHi4Ro8ereDgYEeAe+ihh4q9jFPcJdui9+CFHiJ4JY4lqgbmvADnee+991RQUKA77rjD5TJNkaNHj+rVV1/VZ599Jkm6/vrrdc8992jhwoW65ZZbdPz4cccj5i/0ZNPS2rNnj0vb119/Lens5aMiHh4exQad9PR0l7aS9K1oBKloW+c6ffq0vvvuO11zzTVO81MuR9Flt+K2l5qaKkkXDZWXa/369brmmmsUHx+vW265xRFc8vPzHd/TS40etWrVShaLRd99953LawcOHHD6xezr66uGDRvqwIED+uuvv1zq165dq/j4eMddWmV9Pw0YMEA5OTn64osvtGHDBklymtdjtVqVnJys1q1b66WXXlL79u0dYSAjI0N5eXmX3O8LWb9+vdzd3fX666+rS5cujuBiGIYOHjzo+Pe5Svp+P1dpjyXMi/ACnOOLL75QQkKCvLy89NBDD12wrkaNGlq4cKHmzJnjNIfj9OnTOnHihDw9PR2XeYoC0LnPBymL77//3vFLRzr7V/3MmTNlsVicnmh6ww036NixY05/zWZkZDgmwp6rqG/nPyvmXO3bt1fjxo21ceNGpaSkONrtdrvi4uKUnZ2tfv36XXLSZkkVzcF47bXXHJdfpLPPJJk1a5ZjDkdFqVGjhv766y+nZ5QUFhbqlVdecYxeXex4SWcnF0dERGj79u1KTk52tJ8+fbrYW60HDhyo7OxszZw50+mX+IEDB/Tiiy9q0aJFjtGmovkypX0/3XnnnfLw8NDmzZu1efNmhYWFqXHjxo7XPT095e7uLqvV6vSezs/P14svvlii/b6QGjVqqLCw0GXC7/z58x1B4vz92bx5s1OA/f3335WYmChPT0/dddddF9xWaY4lzIvLRrgqbdq0yTGvxTAM5eTkaO/evdq1a5dq1KihWbNmOU0+Pd91112nUaNGadGiRerbt6+6dOkiNzc3bdu2TQcPHtTYsWMdlw7q168vSXrnnXf0559/atiwYWXqc9OmTfX444/rk08+kb+/vz777DMdO3ZMMTExatOmjaPu3nvv1UsvveR4Pslff/2ljz/+WIGBgdq1a5fTOov69sYbb2jv3r3FPifF3d1d06dP1+jRoxUTE6Pbb79dDRs2VGpqqvbs2aObb77Z5c6Oy9GxY0cNHz5c//M//6N+/fqpa9euKiws1ObNm3Xy5ElNmDChRPOJyqpfv35auHCh7r77bnXv3l0FBQVKSUnR4cOH5e/vr6ysLGVnZxc7J+Nc//rXv/TPf/5TjzzyiLp376569eopJSXFEcjODXsxMTHatm2b3n77baWmpqpDhw6yWq3asGGDTp06penTpztGgOrUqSNPT0/t2LFD06dPV/fu3S/46P9z1a5dW7fddpv+3//7fzp16pTLhxnWqFFDPXr00IYNG3TPPfcoIiJCeXl5+uyzz/THH3+oVq1aysnJkd1uL3VQ7devn7799lvdd999uuOOO+Th4aEdO3Zoz549uuaaa5SZmeny7Jvrr79e0dHRuvPOO+Xp6amkpCT98ccfev755x3v2+KU5ljCvAgvuCoV/fVZpGbNmmrYsKGGDRumkSNHqkmTJpdcxxNPPKEmTZpo5cqVWrNmjQoLC9WiRQtNnz7daTi+Q4cOGjp0qNatW6dly5apU6dOF7wcdTHdunXTjTfeqMTERGVkZKhZs2Z6+eWXdc899zjVDRs2TIWFhVqxYoXeeecdNWjQQA899JA6derk8pkzffr0UXJysrZs2aIVK1Zc8IP+wsLCtHLlSiUkJOjLL79UcnKy4/OCRo8eXaJJm6Xx73//W61atdKKFSu0bt06eXh4qFWrVoqOjnb6wMyKMH78eHl5eWn9+vVasWKF/P391bx5c/373//WwYMHNXXqVCUnJ7sc9/PdcMMNeuedd/Taa69p+/btKigo0C233KLZs2erX79+TrdWV69eXUuXLtVbb72ljz76SCtWrJCvr6/at2+vmJgYp8+68vT01JQpUzR37lwtX75cPj4+JQov0tlRraSkJNWsWVO9e/d2ef2VV15RvXr1tGnTJi1btkzXXXedgoODFRMTow8++EBLlizRjh071KlTpxIezbOGDBki6ewTc1euXClfX18FBARo5syZql69usaOHavk5GSnO8yGDx+u/Px8LV++XJmZmQoMDNQLL7yg7t27X3RbpTmWMC+LUdaLmACAYtntdh09elTXX3+9y6Tto0ePqnv37rrvvvv0/PPPV04HAZNjzgsAlLOiDzq86667XJ5rs3DhQkliBAC4DFw2AoByZrFYNHjwYC1atEj9+vVTVFSU3N3d9fXXX+vbb79VZGRksZdtAJQMl40AoAIUfYzBypUrdfjwYRUUFKhRo0a66667FB0dXa7PAAKuNoQXAABgKsx5AQAApkJ4AQAApkJ4AQAApsLdRhXAMAzZ7UwlAgCgNNzcLCX6/C7CSwWw2w1lZbl+IioAALgwf39vubtfOrxw2QgAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgK4QUAAJgKH8xoMm5uFrm5XfpDqwAzs9v5ZHYAF0Z4MRE3N4tq1/aSuzsDZvh7Kyy0Kzs7jwADoFiEFxNxc7PI3d1NCe98rozf/6zs7gAVomHdWhp7X4Tc3CyEFwDFIryYUMbvfyot42RldwMAgErB9QcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqhBcAAGAqVT68xMbG6vbbb3dqO3TokGJiYhQaGqqOHTvqmWeekdVqdarJzc3VlClTFBERoXbt2ik6OloHDhxwWf/ixYvVvXt3BQcHq3///tq0aVOF7g8AALg8VTq8rFu3TklJSU5tVqtVo0aNUlZWluLi4jRx4kQlJSVp/PjxTnVF7RMnTlRcXJwyMzM1cuRIZWdnO2reeustzZgxQwMHDtS8efPUtGlTjRs3TqmpqVdg7wAAQFlUq+wOXMjx48f1yiuvqH79+k7t77zzjqxWq9auXSt/f39JUr169RQTE6Ndu3YpLCxM33zzjbZs2aIFCxaoS5cukqSwsDB169ZNK1as0JgxY5Sfn6/ExESNGjVKY8eOlSRFRUVp8ODBSkhI0Ntvv31F9xcAAJRMlR15+fe//62IiAh16tTJqT0lJUWhoaGO4CJJnTt3lre3t7Zu3eqo8fLyUkREhKPG399fHTp0cNTs3r1bVqtVPXv2dNRYLBb16NFDO3fuVH5+fkXuHgAAKKMqGV5WrlypPXv26Nlnn3V57eDBgwoICHBqc3NzU6NGjZSWluaoadSokapVcx5YatKkiQ4fPuyokaRmzZo51TRt2lSFhYVKT08vp70BAADlqcpdNsrIyNC0adM0bdo0p9GVIlarVd7e3i7t3t7eys3NlSTl5OTIx8en2BqbzeaokeRSV7TuonWVVbVq5Z8L3d2rZNYEKgTvdwAXUqXCi2EYeuaZZ9SlSxf16tXrgnUWi6XYZYva7XZ7sTXnLmu32y/YB+nsaE5ZublZVKeOa8ACUHJ+fjUruwsAqqgqFV6WL1+u/fv3a/369SooKJD0f2GioKBAbm5u8vHxKXZUJC8vzzG519fXV5mZmS41NptNvr6+kiQ/Pz9HW61atZzWU7SOsrLbDVmteWVe/kLc3d34gY6rhtV6SoWFxf+RAeDvyc+vZolGXatUeNm4caNOnjypyMhIl9datWql2NhYBQQEuMxHsdvtOnbsmGPybUBAgFJSUmS3251GUNLT09W8eXNHjSQdOXJEbdq0cdQcOXJEnp6eaty48WXtS0EBP3SBy1FYaOc8AlCsKhVeXnjhBceclCIJCQn64Ycf9Prrr6tu3bqyWCxauHChsrKyHHNitm3bJpvN5ri7KDIyUm+88Ya2bdvmuFU6KytLqampevjhhyVJISEh8vLy0saNGx3hxTAMJSUlKTw8XJ6enldqtwEAQClUqfByww03uLTVrl1bnp6eCg4OliQNGTJEy5YtU3R0tGJjY5Wdna0ZM2YoKipKISEhkqQOHTooPDxckyZN0qRJk1S7dm3Fx8fL19dXgwcPliTVrFlT999/vxISEuTh4aGQkBCtWrVKe/bs0ZIlS67cTgMAgFKpUuGlJPz9/bV06VJNnTpVTzzxhLy9vdW7d29NnjzZqW7evHmaPn264uLiZLfb1b59e82ePdtpfktsbKzc3d31/vvva9GiRWrRooXmz5+v0NDQK71bAACghCxG0YxYlJvCQruysmyXLiylatXcVKeOt56Z85HSMk6W+/qBqqBZwzqa+lgfnTxpY84LcJXx9/cu0YRdHqQAAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMhfACAABMpVpldwAA/k7c3Cxyc7NUdjeACmW3G7LbjUrbPuEFAMqJm5tFderUlJube2V3BahQdnuhTp48VWkBhvACAOXk7KiLuw5/8KZOZf5a2d0BKkTNaxoooO+DcnOzEF4A4O/iVOavOnU8vbK7AfxtMWEXAACYCuEFAACYCuEFAACYCuEFAACYCuEFAACYCuEFAACYCuEFAACYCuEFAACYCuEFAACYCuEFAACYSpULL4WFhVqwYIF69OihNm3aqF+/flq3bp1TzaFDhxQTE6PQ0FB17NhRzzzzjKxWq1NNbm6upkyZooiICLVr107R0dE6cOCAy/YWL16s7t27Kzg4WP3799emTZsqdP8AAMDlqXLhZebMmZo7d67uueceJSYm6tZbb9XkyZO1fv16SZLVatWoUaOUlZWluLg4TZw4UUlJSRo/frzTeoraJ06cqLi4OGVmZmrkyJHKzs521Lz11luaMWOGBg4cqHnz5qlp06YaN26cUlNTr+AeAwCA0qhSH8xos9m0bNkyjRw5UjExMZKkTp06ac+ePVq2bJnuuusuvfPOO7JarVq7dq38/f0lSfXq1VNMTIx27dqlsLAwffPNN9qyZYsWLFigLl26SJLCwsLUrVs3rVixQmPGjFF+fr4SExM1atQojR07VpIUFRWlwYMHKyEhQW+//XalHAMAAHBxVWrkpXr16nrvvfcUHR3t1O7h4aHTp09LklJSUhQaGuoILpLUuXNneXt7a+vWrY4aLy8vRUREOGr8/f3VoUMHR83u3btltVrVs2dPR43FYlGPHj20c+dO5efnV9h+AgCAsqtS4aVatWpq2bKlrr32WhmGoRMnTigxMVHbt2/XkCFDJEkHDx5UQECA03Jubm5q1KiR0tLSHDWNGjVStWrOA0tNmjTR4cOHHTWS1KxZM6eapk2bqrCwUOnpfJw9AABVUZW6bHSu9evXa9KkSZKkLl26qE+fPpLOznnx9vZ2qff29lZubq4kKScnRz4+PsXW2Gw2R40kl7qidRetq6yqVSv/XOjuXqWyJlChzPh+N2OfgbKqzPd7lQ0vbdu21bJly3T48GHNnTtXgwcP1n//+19JZy/vnM8wDEe73W4vtubcZe12e7GvG4Yh6exoTlm5uVlUp45rwAJQcn5+NSu7CwAuojLP0SobXpo2baqmTZuqQ4cOaty4sUaNGqWNGzfKx8en2FGRvLw81a9fX5Lk6+urzMxMlxqbzSZfX19Jkp+fn6OtVq1aTuspWkdZ2e2GrNa8Mi9/Ie7ubvxAx1XDaj2lwsLi/8ioqjhHcTWpiHPUz69miUZ0qlR4yczM1NatWxUVFaVrrrnG0R4cHCxJ+u233xQQEOAyH8Vut+vYsWOOybcBAQFKSUmR3W53GkFJT09X8+bNHTWSdOTIEbVp08ZRc+TIEXl6eqpx48aXtS8FBeb6oQtUNYWFds4joAqrzHO0Sl2gzcvL01NPPaWVK1c6tW/btk2SFBQUpIiICKWmpiorK8vpdZvN5ri7KDIyUjabzbGcJGVlZSk1NVWRkZGSpJCQEHl5eWnjxo2OGsMwlJSUpPDwcHl6elbYfgIAgLKrUiMvjRs31oABA5SQkCA3NzcFBwfrhx9+0Ouvv67IyEhFRUUpODhYy5YtU3R0tGJjY5Wdna0ZM2YoKipKISEhkqQOHTooPDxckyZN0qRJk1S7dm3Fx8fL19dXgwcPliTVrFlT999/vxISEuTh4aGQkBCtWrVKe/bs0ZIlSyrzMAAAgIuoUuFFkl566SU1a9ZMq1atUnx8vK677jqNGDFCY8aMkcVikb+/v5YuXaqpU6fqiSeekLe3t3r37q3Jkyc7rWfevHmaPn264uLiZLfb1b59e82ePdtpfktsbKzc3d31/vvva9GiRWrRooXmz5+v0NDQK73bAACghCxG0e01KDeFhXZlZdnKfb3VqrmpTh1vPTPnI6VlnCz39QNVQbOGdTT1sT46edJmujkvRefo3iUv6tRxnhWFv6ea9Zro5pFTKuQc9ff3LtGE3So15wUAAOBSCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUKjy8nDp1qqI3AQAAriJlDi/dunXT0qVLL1qTkJCgrl27lnUTAAAALqqVtDAjI0M5OTlOXx86dEj79u0rtr6goEBffvml8vPzL7+XAAAA/6vE4eX777/X+PHjZbFYJEkWi0Xvvfee3nvvvQsuYxiGIiIiLr+XAAAA/6vE4aV379568MEH9ccff8gwDK1du1YtW7bUTTfdVPyKq1VTvXr1NHTo0HLrLAAAQInDiyRNnDjR8e+dO3dq0KBBGjFiRLl3CgAA4EJKFV7O9emnn5ZnPwAAAEqkzOGlyI4dO5SWlqbTp0/LMIxiaxidAQAA5aXM4SUjI0OjR49WWlqaJF0wuFgsFsILAAAoN2UOL6+++qoOHz6siIgIRUVFydfX13EnEgAAQEUpc3j5/PPP1aFDBy1cuLA8+wMAAHBRZX7C7pkzZ9S2bdvy7AsAAMAllTm8tG7dWnv27CnPvgAAAFxSmcPL448/rl27dmnx4sUqKCgozz4BAABcUJnnvLz//vsKCAhQXFyc5s6dq+uvv16enp4udRaLRatXr76sTgIAABQpc3hZs2aN49+nTp3SwYMHi63jDiQAAFCeyhxeLvRp0gAAABWpzHNeAAAAKsMVGXlp2bJlWTcDAADgpMzhZcCAASWez/Ljjz+WdTMAAABOyj28nDp1Sunp6dq7d6/CwsLUo0ePy+ogAADAucocXqZPn37R1z/77DONGzdODz74YFk3AQAA4KLCJux27dpVt99+u+bNm1dRmwAAAFehCr3bqHHjxvr5558rchMAAOAqU2Hh5fTp00pOTpavr29FbQIAAFyFyjznZdq0acW2G4ahvLw8ffnll8rIyNCwYcPK3DkAAIDzlTm8LFmy5KKvu7u7q0ePHho/fnxZNwEAAOCizOFl6dKlxbZbLBZ5eHioSZMm8vf3L3PHAAAAilPm8BIeHl6e/QAAACiRMoeXIvv379fq1au1b98+5efnq3bt2rrxxhvVt29fPhYAAACUu8sKLwsWLNCcOXNUWFjo1J6cnKzFixfrscceU0xMzGV1EAAA4FxlDi+ffvqpZs6cqcaNG2vcuHEKDQ1V3bp1ZbVatXPnTs2aNUuzZs1Sy5YtFRUVVZ59BgAAV7Eyh5dFixbJ399fy5cvV926dR3t/v7+6t27t0JCQjRgwAC9/fbbhBcAAFBuyvyQur179+r22293Ci7nqlevnrp166YffvihzJ0DAAA4X5nDi91ul7u7+0Vr3N3ddebMmbJuAgAAwEWZw0tgYKC2bNkiq9Va7OvZ2dn67LPPFBgYWObOAQAAnK/M4WXo0KE6fvy4HnjgAe3atUsFBQWSpNzcXG3dulWjRo3SiRMndN9995VbZwEAAMo8Ybd///767rvvtHz5cg0fPlxubm7y9PRUfn6+pLOfcTR8+HANGDCgvPoKAABwec95efbZZ9WrVy+tWbNG+/fvl81mk7e3t1q2bKkBAwaU6Sm8hmHo/fff17Jly3Ts2DH5+/vr9ttv12OPPSYfHx9J0qFDhzR9+nR99dVXqlatmrp166annnpKfn5+jvXk5uYqLi5Omzdvls1mU0hIiP71r3+pRYsWTttbvHixli9fruPHj+uGG27Qo48+qu7du1/OYQEAABXosp+wGx4eXq4fFfDWW29p1qxZeuCBB9SpUycdOXJEc+bM0c8//6zFixcrJydHo0aNUt26dRUXF6fMzEzNmDFDv/32mxYtWuRYz8SJE/Xdd99p0qRJ8vHx0bx58zRy5Eh9+OGHql27tmNbM2fO1NixY9W6dWutWrVK48aN05IlS9ShQ4dy2ycAAFB+yhReDh06pDp16qhOnTour8XHxysiIkLt27cv9XrtdrsWLFigf/7zn5o4caIk6dZbb1Xt2rU1fvx4/fDDD9q+fbusVqvWrl3r+ODHevXqKSYmRrt27VJYWJi++eYbbdmyRQsWLFCXLl0kSWFhYerWrZtWrFihMWPGKD8/X4mJiRo1apTGjh0rSYqKitLgwYOVkJCgt99+uyyHBgAAVLBSTdg9ffq0JkyYoL59+yo5Odnl9aysLCUkJGjo0KEaN26ccnNzS9WZ3Nxc9evXT3379nVqDwgIkCQdPXpUKSkpCg0NdfrE6s6dO8vb21tbt26VJKWkpMjLy0sRERGOGn9/f3Xo0MFRs3v3blmtVvXs2dNRY7FY1KNHD+3cudMxdwcAAFQtJQ4vhYWFGj16tD7++GM1aNCg2FEXT09PPf7442rSpIk++eQTPfzwwzIMo8Sd8fPz07PPPqvQ0FCn9k8++USSdOONN+rgwYOOMOPYCTc3NWrUSGlpaZKkgwcPqlGjRqpWzXlgqUmTJjp8+LCjRpKaNWvmVNO0aVMVFhYqPT29xP0GAABXTokvG7377rvauXOnBg4cqJdeesklGEiSj4+PYmJiNHz4cE2aNEmbN2/Wf//7X91zzz1l7uDXX3+tN998U927d9eNN94oq9Uqb29vlzpvb2/HSE9OTo5jcu/5NTabzVFT1OfzaySVetTofNWqlfku9Atydy//dQJVlRnf72bsM1BWlfl+L3F4Wb9+vRo2bHjB4HKumjVravr06erZs6fWrl1b5vCya9cuPfzww2rSpIleeeUVR7vFYnGpNQzD0W6324utOXdZu91e7OtFI0VubmX/pri5WVSnjmvAAlByfn41K7sLAC6iMs/REoeXn3/+WXfeeeclg0sRHx8fRUZG6tNPPy1Txz788EM99dRTCggI0MKFCx13CPn4+BQ7KpKXl6f69etLknx9fZWZmelSY7PZ5OvrK0mO26ptNptq1arltJ6idZSV3W7Ias0r8/IX4u7uxg90XDWs1lMqLCz+j4yqinMUV5OKOEf9/GqWaESnxOGlsLCw1L/Q69at63jybmm89dZbevXVV9WhQwfNnz/fabsBAQEu81HsdruOHTvmmHwbEBCglJQU2e12pxGU9PR0NW/e3FEjSUeOHFGbNm0cNUeOHJGnp6caN25c6n6fq6DAXD90gaqmsNDOeQRUYZV5jpb42kiDBg1KPYk1PT1d9erVK9Uy7777rmbMmKHevXtr4cKFLoEpIiJCqampysrKcrRt27ZNNpvNcXdRZGSkbDabtm3b5qjJyspSamqqIiMjJUkhISHy8vLSxo0bHTWGYSgpKUnh4eHy9PQsVb8BAMCVUeKRlw4dOmjdunU6ceKErrvuukvWnzhxQlu2bNFtt91W4s6cOHFC06ZNU8OGDTVs2DDt3bvX6fUmTZpoyJAhWrZsmaKjoxUbG6vs7GzNmDFDUVFRCgkJcfQ1PDxckyZN0qRJk1S7dm3Fx8fL19dXgwcPlnR2Xs7999+vhIQEeXh4KCQkRKtWrdKePXu0ZMmSEvcZAABcWSUOL4MHD9bKlSs1btw4vfnmm8XezVMkNzdXjz76qM6cOeMICyWRnJys/Px8ZWRkaOjQoS6vT5s2TYMGDdLSpUs1depUPfHEE/L29lbv3r01efJkp9p58+Zp+vTpiouLk91uV/v27TV79myn+S2xsbFyd3fX+++/r0WLFqlFixaaP3++y63aAACg6rAYpXgQy5w5c/T666/r2muv1dChQxUREaGAgAB5e3vrzz//VHp6ulJSUrR8+XJlZWXp7rvvdrpL6GpRWGhXVpat3NdbrZqb6tTx1jNzPlJaxslyXz9QFTRrWEdTH+ujkydtppvzUnSO7l3yok4d51lR+HuqWa+Jbh45pULOUX9/7/KdsCtJ48aNk4eHh+bPn6+5c+dq7ty5LjWGYcjDw0MPPvigJkyYUJrVAwAAXFKpwovFYtGYMWPUp08frVmzRikpKfrtt99ktVpVu3ZtNW7cWJ07d1bfvn0v+24dAACA4pTpgxmbNWumCRMmMLICAACuOJ5lDQAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATIXwAgAATKVKh5dff/1VYWFh2rFjh1P7oUOHFBMTo9DQUHXs2FHPPPOMrFarU01ubq6mTJmiiIgItWvXTtHR0Tpw4IDLNhYvXqzu3bsrODhY/fv316ZNmyp0nwAAwOWpsuElIyND0dHRysnJcWq3Wq0aNWqUsrKyFBcXp4kTJyopKUnjx493qitqnzhxouLi4pSZmamRI0cqOzvbUfPWW29pxowZGjhwoObNm6emTZtq3LhxSk1NvQJ7CAAAyqJaZXfgfHa7XWvWrFFcXFyxr7/zzjuyWq1au3at/P39JUn16tVTTEyMdu3apbCwMH3zzTfasmWLFixYoC5dukiSwsLC1K1bN61YsUJjxoxRfn6+EhMTNWrUKI0dO1aSFBUVpcGDByshIUFvv/32FdlfAABQOlVu5GX//v16/vnnNWDAgGIDTEpKikJDQx3BRZI6d+4sb29vbd261VHj5eWliIgIR42/v786dOjgqNm9e7esVqt69uzpqLFYLOrRo4d27typ/Pz8itpFAABwGapceGnQoIGSkpL09NNPq0aNGi6vHzx4UAEBAU5tbm5uatSokdLS0hw1jRo1UrVqzgNLTZo00eHDhx01ktSsWTOnmqZNm6qwsFDp6enltEcAAKA8VbnLRrVr177o61arVd7e3i7t3t7eys3NlSTl5OTIx8en2BqbzeaokeRSV7TuonWVVbVq5Z8L3d2rXNYEKowZ3+9m7DNQVpX5fq9y4aUkLBaLS5thGI52u91ebM25y9rt9mJfNwxD0tnRnLJyc7OoTh3XgAWg5Pz8alZ2FwBcRGWeo6YLLz4+PsWOiuTl5al+/fqSJF9fX2VmZrrU2Gw2+fr6SpL8/PwcbbVq1XJaT9E6yspuN2S15pV5+Qtxd3fjBzquGlbrKRUWFv9HRlXFOYqrSUWco35+NUs0omO68BIQEOAyH8Vut+vYsWOOybcBAQFKSUmR3W53GkFJT09X8+bNHTWSdOTIEbVp08ZRc+TIEXl6eqpx48aX1c+CAnP90AWqmsJCO+cRUIVV5jlqugu0ERERSk1NVVZWlqNt27ZtstlsjruLIiMjZbPZtG3bNkdNVlaWUlNTFRkZKUkKCQmRl5eXNm7c6KgxDENJSUkKDw+Xp6fnFdojAABQGqYbeRkyZIiWLVum6OhoxcbGKjs7WzNmzFBUVJRCQkIkSR06dFB4eLgmTZqkSZMmqXbt2oqPj5evr68GDx4sSapZs6buv/9+JSQkyMPDQyEhIVq1apX27NmjJUuWVOYuAgCAizBdePH399fSpUs1depUPfHEE/L29lbv3r01efJkp7p58+Zp+vTpiouLk91uV/v27TV79myn+S2xsbFyd3fX+++/r0WLFqlFixaaP3++QkNDr/RuAQCAErIYRbfXoNwUFtqVlWUr9/VWq+amOnW89cycj5SWcbLc1w9UBc0a1tHUx/ro5Emb6ea8FJ2je5e8qFPHeVYU/p5q1muim0dOqZBz1N/fu0QTdk035wUAAFzdCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC8AAMBUCC+Stm7dqkGDBqlt27bq2rWrEhMTZRhGZXcLAAAU46oPL19//bXGjBmj5s2bKz4+Xv369dOsWbP0xhtvVHbXAABAMapVdgcqW0JCglq2bKkZM2ZIkqKiolRQUKAFCxYoOjpaNWrUqOQeAgCAc13VIy+nT5/Wjh071LNnT6f2Xr16KS8vT7t27aqkngEAgAu5qsPL0aNHdebMGTVr1sypvWnTppKktLS0K98pAABwUVf1ZSOr1SpJ8vHxcWr39vaWJOXm5pZpvW5uFvn7e19e54phsZz9/5MP3K7CQnu5rx+oCtzdz/5NVatWTZlt3nzROXrjP8bLsBdWbmeACmJxc5dUMeeom5ulRHVXdXix288GAIul+IPl5la2gSmLxSJ395J9A8qilg/zcPD3V9bzryrw8Par7C4AFa4yz1Hz/nQoB35+Z3/AnD/CYrPZJLmOyAAAgMp3VYeXJk2ayN3dXUeOHHFqL/q6RYsWldEtAABwEVd1eKlevbrCwsKUlJTk9FC6jRs3ys/PT23atKnE3gEAgOJc1eFFkh555BHt3r1bjz32mJKTkzV79mwtXLhQDz30EM94AQCgCrIYPAdfSUlJmjt3rg4fPqx69epp6NChuv/++yu7WwAAoBiEFwAAYCpX/WUjAABgLoQXAABgKoQXAABgKoQXAABgKoQXAABgKoQXAABgKoQXAABgKoQX4AK2bt2qQYMGqW3bturatasSExPFY5GAqufXX39VWFiYduzYUdldwRVCeAGK8fXXX2vMmDFq3ry54uPj1a9fP82aNUtvvPFGZXcNwDkyMjIUHR2tnJycyu4KrqBqld0BoCpKSEhQy5YtNWPGDElSVFSUCgoKtGDBAkVHR/O5V0Als9vtWrNmjeLi4iq7K6gEjLwA5zl9+rR27Nihnj17OrX36tVLeXl52rVrVyX1DECR/fv36/nnn9eAAQMIMFchwgtwnqNHj+rMmTNq1qyZU3vTpk0lSWlpaVe+UwCcNGjQQElJSXr66acZCb0KcdkIOI/VapUk+fj4OLV7e3tLknJzc694nwA4q127dmV3AZWIkRfgPHa7XZJksViKfd3NjdMGACoTP4WB8/j5+UlyHWGx2WySXEdkAABXFuEFOE+TJk3k7u6uI0eOOLUXfd2iRYvK6BYA4H8RXoDzVK9eXWFhYUpKSnJ6KN3GjRvl5+enNm3aVGLvAACEF6AYjzzyiHbv3q3HHntMycnJmj17thYuXKiHHnqIOxsAoJIRXoBidOrUSfHx8Tp8+LDGjh2r9evXa/LkyRo9enRldw0ArnoWgw9rAQAAJsLICwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMBXCCwAAMJVqld0BAIiPj9e8efNKVNuwYUN9+umnFdyjstuzZ4+ys7MVERFR2V0B/rYILwAqXXh4uGJjY53a1qxZo4yMDI0YMcLxSd+S5Ovre6W7V2LJycl6+OGH9eSTTxJegApEeAFQ6Tp27KiOHTs6te3cuVMZGRkaOXKkGjVqVEk9K53MzEzZ7fbK7gbwt8ecFwAAYCqEFwCmsn//fk2aNEldunRR69at1b59ew0ePFgff/yxU91TTz2loKAg7d69W7169VJwcLAGDx6soo9z++KLLzR8+HCFhobqlltu0ZQpU/TTTz8pKChI8fHxTus6ceKEnn/+eUVFRal169a6/fbbNWPGDOXm5jpt7+mnn5YkTZs2TUFBQTp27FgFHw3g6sRlIwCm8d1332n48OHy9PRUz5495e/vryNHjmjz5s0aP368PD091a1bN6dlHnnkEbVt21ZRUVHy8vKSxWLRxo0bNWHCBHl5ealnz56qWbOmPvzwQ23fvt1lm7/88ovuu+8+/f777+ratatuuOEG7du3T2+99Za2b9+u5cuXy8vLS927d5fVatXmzZsVGRmpdu3aOc3VAVB+CC8ATGPOnDkqKCjQ6tWr1bx5c0f7hg0b9Nhjj+nDDz90CS+hoaFOIyl5eXl64YUX5OXlpZUrVyogIECSNHr0aA0cONBlm88//7yOHz+uBQsWKCoqytG+bNkyvfTSS0pISNCkSZOcwkvnzp01atSoct57AEW4bATANEaNGqUZM2Y4BRdJuuWWWyRJWVlZLsv07NnT6ett27YpMzNTw4YNcwQXSbr++usVHR3tVPv7779r69atuu2225yCiyQNHTpUDRo00OrVqy9rnwCUHiMvAEyjc+fOks7OQdm3b5/S09N18OBBffPNN5KkwsJCl2XOv1Pphx9+kCS1a9fOpbZ9+/ZOX+/du1eGYejkyZMu82AkycPDQ7/++quOHz+uevXqlWmfAJQe4QWAafz666966aWX9Omnn8owDLm7u6tZs2YKCwvT3r17i12mRo0aTl+fPHlSknTNNde41NatW9fpa6vVKkn69ttv9e23316wX9nZ2YQX4AoivAAwBcMwFBMTowMHDujBBx9Ur169FBgYKE9PT2VlZem9994r0Xp8fHwkyelOoSLnt3l5eUmSxowZo8cee+wy9wBAeWHOCwBT2Ldvn3766Sf16NFDEydOVOvWreXp6SlJOnDggCQ5boO+mFatWkk6e+fS+Xbv3u30dcuWLSWdfeR/cebOnasFCxbo9OnTkiSLxVLCvQFwOQgvAEyhevXqks4+xfZc2dnZ+s9//iNJKigouOR6unXrptq1a+t//ud/dPToUUf7b7/9poULFzrVNmrUSOHh4UpOTlZSUpLTa2vXrlVCQoKSk5MdIcrd3b3E/QBQdlw2AmAKAQEBatOmjXbt2qUhQ4aoffv2OnnypDZt2qTTp0+rZs2ajvksF+Pl5aUpU6Zo4sSJuvvuu9WjRw+5ubk5hRM3t//7u+7FF1/UkCFD9OijjyoqKkotWrTQ4cOHtWXLFtWqVUvPPfeco7Z+/fqSpHfeeUd//vmnhg0bxlwYoAIw8gLAFCwWi+bPn69Bgwbp2LFjWrp0qVJTUxUVFaVVq1YpIiJCaWlpSk9Pv+S67rzzTs2fP1/NmjXTBx98oE8++UR9+vTRlClTJEk1a9Z01AYEBGj16tW65557tG/fPi1dulT79+9X//79tXLlSgUGBjpqO3TooKFDhyo7O1vLli3TwYMHy/9AAJDFKMlFYgD4m8jNzZXNZlPdunVd5qisWrVKzzzzjGbNmqU+ffpUUg8BXAojLwCuKocPH1ZUVJSeeeYZp/b8/HwtX75c1apVU2hoaCX1DkBJMOcFwFWlVatWCg4O1urVq3Xs2DG1adNG+fn5+uyzz5SRkaEJEyYwTwWo4rhsBOCqk5OTo8WLF2vDhg365Zdf5OHhoaCgIA0bNky9e/eu7O4BuATCCwAAMBXmvAAAAFMhvAAAAFMhvAAAAFMhvAAAAFMhvAAAAFMhvAAAAFMhvAAAAFMhvAAAAFMhvAAAAFP5/x8+IuEDcw/ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 7: Visualize the target distribution in the train set\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='target', data=train_data)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'keyword', 'location', 'text', 'target'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief description of the problem and data\n",
    "\n",
    "1. **Dataset Sizes**:\n",
    "   - The training set has 7,613 samples and 5 columns.\n",
    "   - The test set has 3,263 samples and 4 columns (excluding the target column).\n",
    "     \n",
    "\n",
    "2. **Missing Values**:\n",
    "   - In the training set, the `keyword` column has 61 missing values, and the `location` column has 2,533 missing values.\n",
    "   - In the test set, the `keyword` column has 26 missing values, and the `location` column has 1,105 missing values.\n",
    "   - Both the `text` and `id` columns have no missing values in either dataset.\n",
    "     \n",
    "\n",
    "3. **Target Distribution**:\n",
    "   - In the training set, there are 4,342 samples labeled as `0` (non-disaster tweets) and 3,271 samples labeled as `1` (disaster tweets).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Handling Missing Values\n",
    "# For simplicity, we'll fill missing 'keyword' and 'location' with placeholder text\n",
    "train_data['keyword'].fillna('missing_keyword', inplace=True)\n",
    "train_data['location'].fillna('missing_location', inplace=True)\n",
    "test_data['keyword'].fillna('missing_keyword', inplace=True)\n",
    "test_data['location'].fillna('missing_location', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "keyword     0\n",
       "location    0\n",
       "text        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Basic Text Cleaning\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "train_data['clean_text'] = train_data['text'].apply(clean_text)\n",
    "test_data['clean_text'] = test_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned text preview in train set:\n",
      "                                                text                                         clean_text\n",
      "0  Our Deeds are the Reason of this #earthquake M...  our deeds are the reason of this earthquake ma...\n",
      "1             Forest fire near La Ronge Sask. Canada              forest fire near la ronge sask canada\n",
      "2  All residents asked to 'shelter in place' are ...  all residents asked to shelter in place are be...\n",
      "3  13,000 people receive #wildfires evacuation or...  people receive wildfires evacuation orders in ...\n",
      "4  Just got sent this photo from Ruby #Alaska as ...  just got sent this photo from ruby alaska as s...\n",
      "\n",
      "Cleaned text preview in test set:\n",
      "                                                text                                         clean_text\n",
      "0                 Just happened a terrible car crash                 just happened a terrible car crash\n",
      "1  Heard about #earthquake is different cities, s...  heard about earthquake is different cities sta...\n",
      "2  there is a forest fire at spot pond, geese are...  there is a forest fire at spot pond geese are ...\n",
      "3           Apocalypse lighting. #Spokane #wildfires              apocalypse lighting spokane wildfires\n",
      "4      Typhoon Soudelor kills 28 in China and Taiwan         typhoon soudelor kills in china and taiwan\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preview the cleaned text\n",
    "print(\"\\nCleaned text preview in train set:\")\n",
    "print(train_data[['text', 'clean_text']].head())\n",
    "\n",
    "print(\"\\nCleaned text preview in test set:\")\n",
    "print(test_data[['text', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine keyword, location, and clean_text\n",
    "train_data['combined_text'] = train_data['keyword'] + ' ' + train_data['location'] + ' ' + train_data['clean_text']\n",
    "test_data['combined_text'] = test_data['keyword'] + ' ' + test_data['location'] + ' ' + test_data['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       missing_keyword missing_location our deeds are...\n",
       "1       missing_keyword missing_location forest fire n...\n",
       "2       missing_keyword missing_location all residents...\n",
       "3       missing_keyword missing_location people receiv...\n",
       "4       missing_keyword missing_location just got sent...\n",
       "                              ...                        \n",
       "7608    missing_keyword missing_location two giant cra...\n",
       "7609    missing_keyword missing_location ariaahrary th...\n",
       "7610    missing_keyword missing_location m utckm s of ...\n",
       "7611    missing_keyword missing_location police invest...\n",
       "7612    missing_keyword missing_location the latest mo...\n",
       "Name: combined_text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['combined_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "#### 1. **Logistic Regression**\n",
    "\n",
    "**Architecture**:\n",
    "- **Logistic Regression** is a linear model that is widely used for binary classification problems. It models the probability that a given input belongs to a particular class.\n",
    "\n",
    "**Reasoning**:\n",
    "- **Interpretability**: Logistic Regression is highly interpretable, allowing us to understand the impact of different features on the classification outcome.\n",
    "- **Efficiency**: It is computationally efficient and can handle large datasets well.\n",
    "- **Baseline Model**: Logistic Regression serves as a strong baseline model. If it performs well, more complex models may not be necessary.\n",
    "- **Sparse Data Handling**: Logistic Regression works well with sparse data, which is common when using techniques like TF-IDF for text representation.\n",
    "\n",
    "#### 2. **TF-IDF Vectorizer**\n",
    "\n",
    "**Architecture**:\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)** is a numerical statistic that reflects how important a word is to a document in a collection or corpus. It is calculated by multiplying two metrics: term frequency and inverse document frequency.\n",
    "\n",
    "**Reasoning**:\n",
    "- **Feature Extraction**: TF-IDF is a powerful tool for converting text data into numerical features that can be used in machine learning algorithms.\n",
    "- **Word Importance**: TF-IDF helps highlight important words in the tweets while down-weighting common words that may not carry significant meaning (e.g., \"the\", \"is\", \"at\").\n",
    "- **Handling High Dimensionality**: The resulting vectors are high-dimensional and sparse, making it suitable for linear models like Logistic Regression.\n",
    "- **Context Capture**: By using n-grams (bigrams in this case), TF-IDF can capture some context and phrases, which can improve the model's ability to understand the meaning behind the text.\n",
    "\n",
    "\n",
    "### Model Justification\n",
    "\n",
    "- **Text Data**: Tweets are short text snippets. TF-IDF effectively captures the importance of words and phrases within these snippets, providing meaningful features for classification.\n",
    "- **Sparse Representation**: TF-IDF produces a sparse matrix where most values are zero. Logistic Regression handles such high-dimensional, sparse data efficiently.\n",
    "- **Interpretability**: The simplicity and interpretability of Logistic Regression allow us to gain insights into which words and phrases are significant predictors of disaster-related tweets.\n",
    "- **Scalability**: Logistic Regression scales well to large datasets, which is important given the size of the dataset (10,000 tweets).\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "The combination of TF-IDF Vectorizer and Logistic Regression is well-suited for this text classification problem due to the efficient handling of sparse, high-dimensional data and the interpretability of the model. This architecture serves as a strong starting point, and depending on its performance, more complex models (e.g., ensemble methods or deep learning models) can be considered if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing Text Data\n",
    "vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train = vectorizer.fit_transform(train_data['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "X_test = vectorizer.transform(test_data['combined_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the target values\n",
    "y_train = train_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train: (7613, 10000)\n",
      "Shape of X_test: (3263, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the resulting matrices\n",
    "print(\"\\nShape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data for validation\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.799080761654629\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.83       874\n",
      "           1       0.81      0.70      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Results**\n",
    "\n",
    "The initial Logistic Regression model with TF-IDF vectorization achieved a validation accuracy of 0.7991. Here's a detailed breakdown of the classification report:\n",
    "\n",
    "- Class 0 (Non-disaster tweets):\n",
    "\n",
    "  \n",
    "    - Precision: 0.80\n",
    "    - Recall: 0.88\n",
    "    - F1-score: 0.83\n",
    "\n",
    "\n",
    "- Class 1 (Disaster tweets):\n",
    "    - Precision: 0.81\n",
    "    - Recall: 0.70\n",
    "    - F1-score: 0.75\n",
    "\n",
    "- Overall Metrics:\n",
    "\n",
    "    - Accuracy: 0.80\n",
    "    - Macro Average F1-score: 0.79\n",
    "    - Weighted Average F1-score: 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "Let's start by optimizing the hyperparameters of the Logistic Regression model to see if we can improve its performance.\n",
    "Hyperparameter Optimization Procedure\n",
    "\n",
    "We will use GridSearchCV to find the optimal hyperparameters for Logistic Regression. The hyperparameters we'll tune are:\n",
    "\n",
    "- C: Inverse of regularization strength.\n",
    "- penalty: Regularization technique (L1 or L2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear']},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_split, y_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Best Cross-Validation Score: 0.7973727422003284\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Cross-Validation Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Different Architectures\n",
    "\n",
    "Apart from Logistic Regression, we'll try the following models:\n",
    "\n",
    "1 Random Forest Classifier\n",
    "\n",
    "2 Gradient Boosting Classifier\n",
    "\n",
    "3 Support Vector Machine (SVM)\n",
    "\n",
    "4 Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.7760998030203545\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.90      0.82       874\n",
      "           1       0.82      0.61      0.70       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.79      0.75      0.76      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n",
      "Gradient Boosting Validation Accuracy: 0.7340774786605384\n",
      "\n",
      "Classification Report for Gradient Boosting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.79       874\n",
      "           1       0.78      0.53      0.63       649\n",
      "\n",
      "    accuracy                           0.73      1523\n",
      "   macro avg       0.75      0.71      0.71      1523\n",
      "weighted avg       0.74      0.73      0.72      1523\n",
      "\n",
      "Support Vector Machine Validation Accuracy: 0.8003939592908733\n",
      "\n",
      "Classification Report for Support Vector Machine:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       874\n",
      "           1       0.80      0.71      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.80      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n",
      "Multinomial Naive Bayes Validation Accuracy: 0.8036769533814839\n",
      "\n",
      "Classification Report for Multinomial Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       874\n",
      "           1       0.84      0.66      0.74       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.79      0.79      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "svm_model = SVC(C=1, kernel='linear', random_state=42)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train and evaluate models\n",
    "models = {\n",
    "    'Random Forest': rf_model,\n",
    "    'Gradient Boosting': gb_model,\n",
    "    'Support Vector Machine': svm_model,\n",
    "    'Multinomial Naive Bayes': nb_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"{name} Validation Accuracy: {accuracy}\")\n",
    "    print(f\"\\nClassification Report for {name}:\\n\", classification_report(y_val, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Analysis\n",
    "\n",
    "#### Hyperparameter Tuning Results for Logistic Regression\n",
    "\n",
    "- **Best Parameters**: `{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}`\n",
    "- **Best Cross-Validation Score**: 0.7974\n",
    "\n",
    "#### Model Comparison\n",
    "\n",
    "We compared the performance of various models, including Logistic Regression (with tuned hyperparameters), Random Forest, Gradient Boosting, Support Vector Machine (SVM), and Multinomial Naive Bayes.\n",
    "\n",
    "| Model                     | Validation Accuracy | Precision (Class 0) | Recall (Class 0) | F1-score (Class 0) | Precision (Class 1) | Recall (Class 1) | F1-score (Class 1) |\n",
    "|---------------------------|---------------------|---------------------|------------------|--------------------|---------------------|------------------|--------------------|\n",
    "| Logistic Regression       | 0.7991              | 0.80                | 0.88             | 0.83               | 0.81                | 0.70             | 0.75               |\n",
    "| Random Forest             | 0.7761              | 0.76                | 0.90             | 0.82               | 0.82                | 0.61             | 0.70               |\n",
    "| Gradient Boosting         | 0.7341              | 0.72                | 0.89             | 0.79               | 0.78                | 0.53             | 0.63               |\n",
    "| Support Vector Machine    | 0.8004              | 0.80                | 0.86             | 0.83               | 0.80                | 0.71             | 0.75               |\n",
    "| Multinomial Naive Bayes   | 0.8037              | 0.78                | 0.91             | 0.84               | 0.84                | 0.66             | 0.74               |\n",
    "\n",
    "### Analysis of Model Performance\n",
    "\n",
    "1. **Logistic Regression**:\n",
    "   - **Validation Accuracy**: 0.7991\n",
    "   - Logistic Regression remains a robust choice, with a well-balanced precision and recall, particularly strong on non-disaster tweets.\n",
    "\n",
    "2. **Random Forest**:\n",
    "   - **Validation Accuracy**: 0.7761\n",
    "   - High precision for disaster-related tweets but lower recall, indicating the model might be missing some disaster-related tweets.\n",
    "\n",
    "3. **Gradient Boosting**:\n",
    "   - **Validation Accuracy**: 0.7341\n",
    "   - Lower accuracy and F1 scores compared to other models, indicating it may not be as effective for this particular problem.\n",
    "\n",
    "4. **Support Vector Machine (SVM)**:\n",
    "   - **Validation Accuracy**: 0.8004\n",
    "   - Performs similarly to Logistic Regression with a balanced precision and recall, showing it can be an effective model for this task.\n",
    "\n",
    "5. **Multinomial Naive Bayes**:\n",
    "   - **Validation Accuracy**: 0.8037\n",
    "   - Slightly higher accuracy than Logistic Regression, with strong performance on both precision and recall for non-disaster tweets.\n",
    "\n",
    "### Improvements and Techniques Applied\n",
    "\n",
    "1. **Hyperparameter Tuning**:\n",
    "   - Used GridSearchCV for Logistic Regression to find optimal hyperparameters, which improved the model's performance to a cross-validation score of 0.7974.\n",
    "\n",
    "2. **Feature Engineering**:\n",
    "   - Combined `keyword`, `location`, and `clean_text` into a single `combined_text` feature to provide more context for the model.\n",
    "\n",
    "3. **Advanced Vectorization Techniques**:\n",
    "   - Used TF-IDF Vectorization with n-grams to capture more context from the tweets, which improved the performance of the models.\n",
    "\n",
    "4. **Model Comparison**:\n",
    "   - Experimented with different models to identify the best-performing one. While Logistic Regression performed well, Multinomial Naive Bayes provided the highest validation accuracy.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Based on the validation accuracy and the detailed analysis of precision, recall, and F1 scores, **Multinomial Naive Bayes** emerged as the best-performing model for this specific task, with a validation accuracy of 0.8037. \n",
    "\n",
    "- **Logistic Regression** and **Support Vector Machine** also performed competitively, making them viable options depending on the specific requirements (e.g., interpretability, efficiency).\n",
    "- **Random Forest** and **Gradient Boosting** provided decent performance but were not as effective for this problem, possibly due to the nature of the dataset and the importance of capturing text-based features.\n",
    "\n",
    "### Future Work\n",
    "\n",
    "- **Further Hyperparameter Tuning**: Continue to fine-tune hyperparameters for models like Random Forest and Gradient Boosting.\n",
    "- **Advanced NLP Techniques**: Explore more sophisticated text embeddings such as Word2Vec, GloVe, or transformer-based models like BERT.\n",
    "- **Ensemble Methods**: Combine predictions from multiple models to create a more robust classifier.\n",
    "- **Data Augmentation**: Increase the dataset size through data augmentation techniques to provide more training data for the models.\n",
    "\n",
    "By iterating on these approaches, the disaster tweet classification system can be further refined to achieve even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code done by Dennis Lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
