{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29cc0557591f5119ed28df4b31530205",
     "grade": false,
     "grade_id": "cell-344b8948f17b670d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "The final score that you will receive for your programming assignment is generated in relation to the total points set in your programming assignment itemâ€”not the total point value in the nbgrader notebook.<br>\n",
    "When calculating the final score shown to learners, the programming assignment takes the percentage of earned points vs. the total points provided by nbgrader and returns a score matching the equivalent percentage of the point value for the programming assignment. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** The autograder will not work properly if you change the variable or method signatures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a5f13a336c857430fd03a6ace8ff3a46",
     "grade": false,
     "grade_id": "cell-d3724f900290df95",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "Please note that this assignment uses nbgrader to facilitate grading. You will see a **validate button** at the top of your Jupyter notebook. If you hit this button, it will run tests cases for the lab that aren't hidden. It is good to use the validate button before submitting the lab. Do know that the labs in the course contain hidden test cases. The validate button will not let you know whether these test cases pass. After submitting your lab, you can see more information about these hidden test cases in the Grader Output. <br>\n",
    "***Cells with longer execution times will cause the validate button to time out and freeze. Please know that if you run into Validate time-outs, it will not affect the final submission grading.*** <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed7c693a3801ad7001a646a0b845090d",
     "grade": false,
     "grade_id": "cell-6f53374656359ce3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 1. Neural Networks\n",
    "This assignment has mixed types of theoretical and code implementation questions on multilayer perceptron and neural network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "import pytest\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9807beb0f33d207bde175ddfcefc3555",
     "grade": false,
     "grade_id": "cell-e9c4e81b1f64c778",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Peer Review] Problem 1 - Single-Layer and Multilayer Perceptron Learning\n",
    "---\n",
    "\n",
    "**Part A** : Answer this question in this week's Peer Review assignment. Consider learning the following concepts with either a single-layer or multilayer perceptron where all hidden and output neurons utilize *indicator* activation functions. For each of the following concepts, state whether the concept can be learned by a single-layer perceptron. Briefly justify your response by providing weights and biases as applicable:\n",
    "\n",
    "i. $~ \\texttt{ NOT } x_1$\n",
    "\n",
    "ii. $~~x_1 \\texttt{ NOR } x_2$\n",
    "\n",
    "iii. $~~x_1 \\texttt{ XNOR } x_2$ (output 1 when $x_1 = x_2$ and 0 otherwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address whether a single-layer perceptron can learn certain logical concepts, we need to analyze the expressiveness of a single-layer perceptron. A single-layer perceptron can only learn linearly separable functions. Let's consider each of the provided logical functions:\n",
    "\n",
    "### i. $\\text{NOT}$, x_1\n",
    "\n",
    "The NOT operation is straightforward for a single-layer perceptron. We can define the perceptron such that:\n",
    "\n",
    "- $(x_1 = 0)$ should output 1.\n",
    "- $(x_1 = 1)$ should output 0.\n",
    "\n",
    "To achieve this, the perceptron can use the following weights and bias:\n",
    "- Weight $(w_1 = -1$)\n",
    "- Bias $(b = 0.5$)\n",
    "\n",
    "The perceptron computes $(y = \\text{indicator}(w_1 \\cdot x_1 + b)$):\n",
    "\n",
    "For $(x_1 = 0$):\n",
    "$y = \\text{indicator}(-1 \\cdot 0 + 0.5) = \\text{indicator}(0.5) = 1 $\n",
    "\n",
    "For $(x_1 = 1$):\n",
    "$ y = \\text{indicator}(-1 \\cdot 1 + 0.5) = \\text{indicator}(-0.5) = 0 $\n",
    "\n",
    "Thus, the NOT operation can be learned by a single-layer perceptron.\n",
    "\n",
    "### ii. $(x_1 \\text{ NOR } x_2$)\n",
    "\n",
    "The NOR operation outputs 1 only when both $(x_1$) and $(x_2$) are 0. Let's define the perceptron:\n",
    "\n",
    "- $(x_1 = 0, x_2 = 0$) should output 1.\n",
    "- Otherwise, it should output 0.\n",
    "\n",
    "The perceptron can use the following weights and bias:\n",
    "- Weights $(w_1 = -1, w_2 = -1$)\n",
    "- Bias $(b = 0.5$)\n",
    "\n",
    "The perceptron computes $(y = \\text{indicator}(w_1 \\cdot x_1 + w_2 \\cdot x_2 + b)$):\n",
    "\n",
    "For $(x_1 = 0, x_2 = 0$):\n",
    "$[ y = \\text{sign}(-1 \\cdot 0 + -1 \\cdot 0 + 0.5) = \\text{indicator}(0.5) = 1$]\n",
    "\n",
    "For $(x_1 = 1, x_2 = 0$):\n",
    "$[ y = \\text{sign}(-1 \\cdot 1 + -1 \\cdot 0 + 0.5) = \\text{indicator}(-0.5) = 0 $]\n",
    "\n",
    "For $(x_1 = 0, x_2 = 1$):\n",
    "$[ y = \\text{sign}(-1 \\cdot 0 + -1 \\cdot 1 + 0.5) = \\text{indicator}(-0.5) = 0 $]\n",
    "\n",
    "For $(x_1 = 1, x_2 = 1$):\n",
    "$[ y = \\text{sign}(-1 \\cdot 1 + -1 \\cdot 1 + 0.5) = \\text{indicator}(-1.5) = 0 $]\n",
    "\n",
    "Thus, the NOR operation can be learned by a single-layer perceptron.\n",
    "\n",
    "### iii. $x_1 \\text{ XNOR } x_2$) (output 1 when $(x_1 = x_2$ and 0 otherwise)\n",
    "\n",
    "The XNOR operation outputs 1 when \\(x_1 = x_2\\) (both 0 or both 1) and 0 otherwise. Let's analyze:\n",
    "\n",
    "- $(x_1 = 0, x_2 = 0$) should output 1.\n",
    "- $(x_1 = 1, x_2 = 1$) should output 1.\n",
    "- $(x_1 = 0, x_2 = 1$) should output 0.\n",
    "- $(x_1 = 1, x_2 = 0$) should output 0.\n",
    "\n",
    "The XNOR function is not linearly separable. The data points (0,0) and (1,1) belong to one class, while (0,1) and (1,0) belong to another class. A single-layer perceptron cannot learn a non-linearly separable function. Therefore, a single-layer perceptron cannot learn the XNOR function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fcdc9c7e4b0ff8c79728408fe31d206",
     "grade": false,
     "grade_id": "cell-ff045cbc37ce40ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B** : Determine an architecture and specific values of the weights and biases in a single-layer or multilayer perceptron with *indicator* activation functions that can learn $x_1 \\texttt{ XNOR } x_2$. <br>\n",
    "In this week's Peer Review, describe your architecture and state your weight matrices and bias vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn the $(x_1 \\text{ XNOR } x_2$) function, we need a multilayer perceptron (MLP) because this function is not linearly separable. We will design a neural network with one hidden layer that can implement this function.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "1. **Input layer:** 2 neurons (corresponding to $(x_1$) and $(x_2$).\n",
    "2. **Hidden layer:** 2 neurons with indicator activation functions.\n",
    "3. **Output layer:** 1 neuron with an indicator activation function.\n",
    "\n",
    "### Step-by-Step Design\n",
    "\n",
    "1. **Input Layer:** The inputs are $(x_1$) and $(x_2$).\n",
    "\n",
    "2. **Hidden Layer:** The hidden layer will have 2 neurons to capture the non-linear combinations of $(x_1$) and $(x_2$). We will set the weights and biases to implement the logic gates.\n",
    "\n",
    "   - **Hidden neuron 1:** Acts as an AND gate for $(x_1 \\text{ AND } x_2)$)\n",
    "     $[\n",
    "     h_1 = \\text{sign}(x_1 + x_2 - 1.5)\n",
    "     $]\n",
    "   - **Hidden neuron 2:** Acts as an OR gate for $(\\text{NOT} \\, x_1 \\text{ AND NOT} \\, x_2)$)\n",
    "     $[\n",
    "     h_2 = \\text{sign}((-x_1) + (-x_2) + 1.5)\n",
    "     $]\n",
    "     \n",
    "\n",
    "3. **Output Layer:** The output layer neuron will combine the outputs of the hidden neurons to implement the XNOR function.\n",
    "   $[\n",
    "   y = \\text{sign}(h_1 + h_2 - 0.5)\n",
    "   $]\n",
    "\n",
    "### Weight Matrices and Bias Vectors\n",
    "\n",
    "**Hidden Layer Weights and Biases:**\n",
    "- For hidden neuron 1 (AND gate):\n",
    "  $[\n",
    "  \\mathbf{W^{(1)}} = \\begin{pmatrix}\n",
    "  1 & 1 \\\\\n",
    "  -1 & -1\n",
    "  \\end{pmatrix}, \\quad \\mathbf{b^{(1)}} = \\begin{pmatrix}\n",
    "  -1.5 \\\\\n",
    "  1.5\n",
    "  \\end{pmatrix}\n",
    "  $]\n",
    "\n",
    "**Output Layer Weights and Bias:**\n",
    "- For the output neuron:\n",
    "  $[\n",
    "  \\mathbf{W^{(2)}} = \\begin{pmatrix}\n",
    "  1 \\\\\n",
    "  1\n",
    "  \\end{pmatrix}, \\quad \\mathbf{b^{(2)}} = -0.5\n",
    "  $]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e25dfa160b71663e07acb99a3f8ed35",
     "grade": false,
     "grade_id": "cell-18ccb1304f92244e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Then demonstrate that your solution is correct by implementing forward propagation for your network in Python and showing that it correctly produces the correct boolean output values for each of the four possible combinations of $x_1$ and $x_2$. <br>\n",
    "Answer the questions about this section in this week's Peer Review assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75b8d9054ed2f46fa506ae7da83894f1",
     "grade": false,
     "grade_id": "cell-bfaabe5488f59154",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0], Output: 1\n",
      "Input: [0 1], Output: 1\n",
      "Input: [1 0], Output: 1\n",
      "Input: [1 1], Output: 1\n"
     ]
    }
   ],
   "source": [
    "# implement forward propagation for network\n",
    "# show that it correctly produces the correct boolean output values \n",
    "# for each of the four possible combinations of x1 and x2 \n",
    "\n",
    "# Initialize x with the 4 possible combinations of 0 and 1 to generate 4 values for y(output)\n",
    "\n",
    "# your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define the activation function\n",
    "def indicator_activation(x):\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "# Define the weights and biases\n",
    "W1 = np.array([[1, 1], [-1, -1]])\n",
    "b1 = np.array([-1.5, 1.5])\n",
    "\n",
    "W2 = np.array([1, 1])\n",
    "b2 = -0.5\n",
    "\n",
    "# Define the forward propagation function\n",
    "def forward_propagation(x):\n",
    "    # Hidden layer\n",
    "    h = indicator_activation(np.dot(x, W1.T) + b1)\n",
    "    # Output layer\n",
    "    y = indicator_activation(np.dot(h, W2) + b2)\n",
    "    return y\n",
    "\n",
    "# Input combinations for x1 and x2\n",
    "inputs = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "# Perform forward propagation for each input\n",
    "outputs = np.array([forward_propagation(x) for x in inputs])\n",
    "\n",
    "# Print the results\n",
    "for i, input_pair in enumerate(inputs):\n",
    "    print(f\"Input: {input_pair}, Output: {outputs[i]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "08ccc87df79d764b8bd2ada03a2ffca6",
     "grade": false,
     "grade_id": "cell-ad9d1e323efa4b80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[15 points, Peer Review] Problem 2 - Back propagation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77f4b8a814fce7fb8a2f19f2b4ee7a87",
     "grade": false,
     "grade_id": "cell-c06610092b8715b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this problem you'll gain some intuition about why training deep neural networks can be very time consuming.  Consider training the chain-like neural network seen below: \n",
    "\n",
    "![chain-like nn](figs/chain_net.png)\n",
    "\n",
    "Note that this network has three weights $W^1, W^2, W^3$ and three biases $b^1, b^2,$ and $b^3$ (for this problem you can think of each parameter as a single value or as a $1 \\times 1$ matrix). Suppose that each hidden and output neuron is equipped with a sigmoid activation function and the loss function is given by \n",
    "\n",
    "$$\n",
    "\\ell(y, a^4) = \\frac{1}{2}(y - a^4)^2  \n",
    "$$\n",
    "\n",
    "where $a^4$ is the value of the activation at the output neuron and $y \\in \\{0,1\\}$ is the true label associated with the training example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "580a73400e366b6514f08e8461c77d61",
     "grade": false,
     "grade_id": "cell-c8989b8ade2901fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part A**: Suppose each of the weights is initialized to $W^k = 1.0$ and each bias is initialized to $b^k = -0.5$.  Use forward propagation to find the activities and activations associated with each hidden and output neuron for the training example $(x, y) = (0.5,0)$. Show your work. Answer the Peer Review question about this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with the parts A, B, and C of the problem step by step. \n",
    "\n",
    "### Part A: Forward Propagation\n",
    "\n",
    "Given the chain-like neural network with sigmoid activation functions, we need to perform forward propagation for the training example $((x, y) = (0.5, 0)$). The weights and biases are initialized as follows:\n",
    "\n",
    "$\n",
    "W^1 = W^2 = W^3 = 1.0 \\quad \\text{and} \\quad b^1 = b^2 = b^3 = -0.5\n",
    "$\n",
    "\n",
    "The sigmoid activation function is defined as:\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "#### Step-by-Step Forward Propagation\n",
    "\n",
    "1. **Input Layer to First Hidden Layer:**\n",
    "\n",
    "   $\n",
    "   z^1 = W^1 x + b^1 = 1.0 \\cdot 0.5 - 0.5 = 0\n",
    "   $\n",
    "\n",
    "   $\n",
    "   a^1 = \\sigma(z^1) = \\sigma(0) = \\frac{1}{1 + e^0} = 0.5\n",
    "   $\n",
    "\n",
    "2. **First Hidden Layer to Second Hidden Layer:**\n",
    "\n",
    "   $\n",
    "   z^2 = W^2 a^1 + b^2 = 1.0 \\cdot 0.5 - 0.5 = 0\n",
    "   $\n",
    "\n",
    "   $\n",
    "   a^2 = \\sigma(z^2) = \\sigma(0) = \\frac{1}{1 + e^0} = 0.5\n",
    "   $\n",
    "\n",
    "3. **Second Hidden Layer to Third Hidden Layer:**\n",
    "\n",
    "   $\n",
    "   z^3 = W^3 a^2 + b^3 = 1.0 \\cdot 0.5 - 0.5 = 0\n",
    "   $\n",
    "\n",
    "   $\n",
    "   a^3 = \\sigma(z^3) = \\sigma(0) = \\frac{1}{1 + e^0} = 0.5\n",
    "   $\n",
    "\n",
    "4. **Third Hidden Layer to Output Layer:**\n",
    "\n",
    "   $\n",
    "   z^4 = W^4 a^3 + b^4 = 1.0 \\cdot 0.5 - 0.5 = 0\n",
    "   $\n",
    "\n",
    "   $\n",
    "   a^4 = \\sigma(z^4) = \\sigma(0) = \\frac{1}{1 + e^0} = 0.5\n",
    "   $\n",
    "\n",
    "So, the activities and activations are:\n",
    "\n",
    "$\n",
    "z^1 = 0, \\quad a^1 = 0.5\n",
    "$\n",
    "$\n",
    "z^2 = 0, \\quad a^2 = 0.5\n",
    "$\n",
    "$\n",
    "z^3 = 0, \\quad a^3 = 0.5\n",
    "$\n",
    "$\n",
    "z^4 = 0, \\quad a^4 = 0.5\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7afad5a4c5c2be4464903b1fafcde38",
     "grade": false,
     "grade_id": "cell-ee509363d6c8add9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Part B**: Use Back-Propagation to compute the weight and bias derivatives $\\partial \\ell / \\partial W^k$ and $\\partial \\ell / \\partial b^k$ for $k=1, 2, 3$.  Show all work. Answer the Peer Review question about this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Backward Propagation\n",
    "\n",
    "To compute the gradients of the loss with respect to the weights and biases, we use backpropagation.\n",
    "\n",
    "The loss function is:\n",
    "\n",
    "$\n",
    "\\ell(y, a^4) = \\frac{1}{2}(y - a^4)^2\n",
    "$\n",
    "\n",
    "For the given example, $(y = 0)$ and $(a^4 = 0.5)$.\n",
    "\n",
    "#### Step-by-Step Backward Propagation\n",
    "\n",
    "1. **Output Layer:**\n",
    "\n",
    "   $[\n",
    "   \\delta^4 = \\frac{\\partial \\ell}{\\partial a^4} \\cdot \\frac{\\partial a^4}{\\partial z^4}\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial a^4} = -(y - a^4) = -(0 - 0.5) = 0.5\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial a^4}{\\partial z^4} = a^4 (1 - a^4) = 0.5 \\cdot (1 - 0.5) = 0.25\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\delta^4 = 0.5 \\cdot 0.25 = 0.125\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial W^3} = \\delta^4 \\cdot a^3 = 0.125 \\cdot 0.5 = 0.0625\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial b^3} = \\delta^4 = 0.125\n",
    "   ]$\n",
    "\n",
    "2. **Third Hidden Layer:**\n",
    "\n",
    "   $[\n",
    "   \\delta^3 = \\delta^4 \\cdot W^3 \\cdot \\frac{\\partial a^3}{\\partial z^3}\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial a^3}{\\partial z^3} = a^3 (1 - a^3) = 0.5 \\cdot (1 - 0.5) = 0.25\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\delta^3 = 0.125 \\cdot 1.0 \\cdot 0.25 = 0.03125\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial W^2} = \\delta^3 \\cdot a^2 = 0.03125 \\cdot 0.5 = 0.015625\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial b^2} = \\delta^3 = 0.03125\n",
    "   ]$\n",
    "\n",
    "3. **Second Hidden Layer:**\n",
    "\n",
    "   $[\n",
    "   \\delta^2 = \\delta^3 \\cdot W^2 \\cdot \\frac{\\partial a^2}{\\partial z^2}\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial a^2}{\\partial z^2} = a^2 (1 - a^2) = 0.5 \\cdot (1 - 0.5) = 0.25\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\delta^2 = 0.03125 \\cdot 1.0 \\cdot 0.25 = 0.0078125\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial W^1} = \\delta^2 \\cdot a^1 = 0.0078125 \\cdot 0.5 = 0.00390625\n",
    "   ]$\n",
    "\n",
    "   $[\n",
    "   \\frac{\\partial \\ell}{\\partial b^1} = \\delta^2 = 0.0078125\n",
    "   ]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbefb76562e8afa6e64e885a0f9bc446",
     "grade": false,
     "grade_id": "cell-7f8e597e7e4b60ed",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART C** Implement following activation functions:\n",
    "\n",
    "Formulas for activation functions\n",
    "\n",
    "* Relu: f($x$) = max(0, $x$)\n",
    "<br><br>\n",
    "\n",
    "* Sigmoid: f($x$) = $\\frac{1}{1 + e^{-x}}$\n",
    "<br><br>\n",
    "\n",
    "* Softmax: f($x_i$) = $\\frac{e^x_i}{\\sum_{j=1}^{n} e^{x_j}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8233dc81204ea9ceb6bf4d797c3c9d0",
     "grade": false,
     "grade_id": "cell-d0c234545c5fc035",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU: [1 2 3]\n",
      "Sigmoid: [0.73105858 0.88079708 0.95257413]\n",
      "Softmax: [0.09003057 0.24472847 0.66524096]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def soft_max(x):\n",
    "    e_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# Test the activation functions\n",
    "x = np.array([1, 2, 3])\n",
    "\n",
    "print(\"ReLU:\", relu(x))\n",
    "print(\"Sigmoid:\", sigmoid(x))\n",
    "print(\"Softmax:\", soft_max(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e5671f427a7dd7fad4788a0f83b7b67",
     "grade": true,
     "grade_id": "cell-abe86f4d2a055610",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Activation function tests\n",
    "# PLEASE NOTE: These sample tests are only indicative and are added to help you debug your code\n",
    "# and there are additional hidden test cases on which your notebook will be evaluated upon submission\n",
    "\n",
    "# Test Relu function\n",
    "assert int(relu(-6.5)) == 0, \"Check relu function\"\n",
    "\n",
    "# Test Sigmoid function\n",
    "assert pytest.approx(sigmoid(0.3), 0.00001) == 0.574442516811659, \"Check sigmoid function\"\n",
    "\n",
    "# Test Softmax function\n",
    "assert pytest.approx(soft_max([5,7]), 0.00001) == [0.11920292, 0.88079708], \"Check softmax function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af687097dc603de58b0b89ca4b352dc0",
     "grade": true,
     "grade_id": "cell-0193f7345d99339c",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests relu, sigmoid, and softmax functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "772c5485fdb83d943fa22f55025a910c",
     "grade": false,
     "grade_id": "cell-219d9e1514d5ceef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART D** Implement the following Loss functions:\n",
    "\n",
    "Formulas for activation functions\n",
    "\n",
    "* Mean squared error <br>\n",
    "Formula: MSE = (1/n) * Î£(yi - yÌ‚i)^2\n",
    "\n",
    "* Mean absolute error <br>\n",
    "Formula: MAE = (1/n) * Î£|yi - yÌ‚i|\n",
    "\n",
    "* Hinge Loss <br>\n",
    "Formula: L = max(0, 1 - yi * yÌ‚i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7946e3115d8ce0995d4d78d8febe9741",
     "grade": false,
     "grade_id": "cell-7837043e5e1e21a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.4025\n",
      "Mean Absolute Error: 0.625\n",
      "Hinge Loss: 0.775\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_squared_error(yhat, y):\n",
    "    \"\"\"\n",
    "    Compute the Mean Squared Error (MSE) between the predicted values yhat and the actual values y.\n",
    "    \n",
    "    Parameters:\n",
    "    yhat (array-like): Predicted values\n",
    "    y (array-like): Actual values\n",
    "    \n",
    "    Returns:\n",
    "    float: The Mean Squared Error\n",
    "    \"\"\"\n",
    "    return np.mean((yhat - y) ** 2)\n",
    "\n",
    "def mean_absolute_error(yhat, y):\n",
    "    \"\"\"\n",
    "    Compute the Mean Absolute Error (MAE) between the predicted values yhat and the actual values y.\n",
    "    \n",
    "    Parameters:\n",
    "    yhat (array-like): Predicted values\n",
    "    y (array-like): Actual values\n",
    "    \n",
    "    Returns:\n",
    "    float: The Mean Absolute Error\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(yhat - y))\n",
    "\n",
    "def hinge(yhat, y):\n",
    "    \"\"\"\n",
    "    Compute the Hinge Loss between the predicted values yhat and the actual values y.\n",
    "    \n",
    "    Parameters:\n",
    "    yhat (array-like): Predicted values\n",
    "    y (array-like): Actual values\n",
    "    \n",
    "    Returns:\n",
    "    float: The Hinge Loss\n",
    "    \"\"\"\n",
    "    return np.mean(np.maximum(0, 1 - y * yhat))\n",
    "\n",
    "# Test the loss functions\n",
    "yhat = np.array([0.5, 0.6, 0.4, 0.8])\n",
    "y = np.array([1, 0, 1, 0])\n",
    "\n",
    "print(\"Mean Squared Error:\", mean_squared_error(yhat, y))\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error(yhat, y))\n",
    "print(\"Hinge Loss:\", hinge(yhat, y))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd9ebe41307ec68147b74b72e1a91e80",
     "grade": true,
     "grade_id": "cell-d9363ea4e62e2041",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Error function tests\n",
    "# PLEASE NOTE: These sample tests are only indicative and are added to help you debug your code\n",
    "# and there are additional hidden test cases on which your notebook will be evaluated upon submission\n",
    "\n",
    "y_true = np.array([2, 3, -0.45])\n",
    "y_pred = np.array([1.5, 3, 0.2])\n",
    "\n",
    "# Test mean squared error function\n",
    "assert pytest.approx(mean_squared_error(y_pred,y_true), 0.00001) == 0.2241666666666667, \"Check mean_squared_error function\"\n",
    "\n",
    "# Test mean absolute error function\n",
    "assert pytest.approx(mean_absolute_error(y_pred,y_true), 0.00001) == 0.3833333333333333, \"Check mean_absolute_error function\"\n",
    "\n",
    "# Test hinge loss function\n",
    "assert pytest.approx(hinge(y_pred,y_true), 0.00001) == 0.36333333333333334, \"Check hinge loss function\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ee2747c222da2f29264feb1da78385d",
     "grade": true,
     "grade_id": "cell-503845fcfe0eb3d2",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# tests mean_squared_error, mean_absolute_error, and hinge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3bb4734dce6230601e9891138145b6a5",
     "grade": false,
     "grade_id": "cell-be3dee9da9a08ec3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[Peer Review] Problem 3 - Build a feed-forward neural network\n",
    "---\n",
    "\n",
    "In this problem you'll implement a general feed-forward neural network class that utilizes sigmoid activation functions. Your tasks will be to implement forward propagation, prediction, back propagation, and a general train routine to learn the weights in your network via stochastic gradient descent.\n",
    "\n",
    "The skeleton for the network class is below. Befor filling out the codes below, read the PART X instruction. The place you will complete the code is indicated as \"TODO\" in the code. Pleaes do not modify other parts of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8adc6c23d42fa75219491344883bcf5",
     "grade": false,
     "grade_id": "cell-4f59cb9a915b1ca3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import colorConverter, ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, sizes):\n",
    "        \"\"\"\n",
    "        Initialize the neural network \n",
    "        \n",
    "        :param sizes: a list of the number of neurons in each layer \n",
    "        \"\"\"\n",
    "        # save the number of layers in the network \n",
    "        self.L = len(sizes) \n",
    "        \n",
    "        # store the list of layer sizes \n",
    "        self.sizes = sizes  \n",
    "        \n",
    "        # initialize the bias vectors for each hidden and output layer \n",
    "        self.b = [np.random.randn(n, 1) for n in self.sizes[1:]]\n",
    "        \n",
    "        # initialize the matrices of weights for each hidden and output layer \n",
    "        self.W = [np.random.randn(n, m) for (m, n) in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "        \n",
    "        # initialize the derivatives of biases for backprop \n",
    "        self.db = [np.zeros((n, 1)) for n in self.sizes[1:]]\n",
    "        \n",
    "        # initialize the derivatives of weights for backprop \n",
    "        self.dW = [np.zeros((n, m)) for (m,n) in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "        \n",
    "        # initialize the activities on each hidden and output layer \n",
    "        self.z = [np.zeros((n, 1)) for n in self.sizes]\n",
    "        \n",
    "        # initialize the activations on each hidden and output layer \n",
    "        self.a = [np.zeros((n, 1)) for n in self.sizes]\n",
    "        \n",
    "        # initialize the deltas on each hidden and output layer \n",
    "        self.delta = [np.zeros((n, 1)) for n in self.sizes]\n",
    "        \n",
    "    def g(self, z):\n",
    "        \"\"\"\n",
    "        sigmoid activation function \n",
    "        \n",
    "        :param z: vector of activities to apply activation to \n",
    "        \"\"\"\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "    \n",
    "    def g_prime(self, z):\n",
    "        \"\"\"\n",
    "        derivative of sigmoid activation function \n",
    "        \n",
    "        :param z: vector of activities to apply derivative of activation to \n",
    "        \"\"\"\n",
    "        return self.g(z) * (1.0 - self.g(z))\n",
    "    \n",
    "    def grad_loss(self, a, y):\n",
    "        \"\"\"\n",
    "        evaluate gradient of cost function for squared-loss C(a,y) = (a-y)^2/2 \n",
    "        \n",
    "        :param a: activations on output layer \n",
    "        :param y: vector-encoded label \n",
    "        \"\"\"\n",
    "        return (a - y)\n",
    "    \n",
    "    def forward_prop(self, x):\n",
    "        \"\"\"\n",
    "        take an feature vector and propagate through network \n",
    "        \n",
    "        :param x: input feature vector \n",
    "        \"\"\"\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.reshape(-1, 1)\n",
    "        # TODO: step 1. Initialize activation on initial layer to x \n",
    "        # your code here\n",
    "        self.a[0] = x\n",
    "        \n",
    "        ## TODO: step 2-4. Loop over layers and compute activities and activations \n",
    "        ## Use Sigmoid activation function defined above\n",
    "        # your code here\n",
    "        for l in range(1, self.L):\n",
    "            self.z[l] = np.dot(self.W[l-1], self.a[l-1]) + self.b[l-1]\n",
    "            self.a[l] = self.g(self.z[l])\n",
    "        \n",
    "    def back_prop(self, x, y):\n",
    "        \"\"\"\n",
    "        Back propagation to get derivatives of C wrt weights and biases for given training example\n",
    "        \n",
    "        :param x: training features  \n",
    "        :param y: vector-encoded label \n",
    "        \"\"\"\n",
    "        \n",
    "        if len(y.shape) == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "        \n",
    "        # TODO: step 1. forward prop training example to fill in activities and activations \n",
    "        # your code here\n",
    "        self.forward_prop(x)\n",
    "        \n",
    "        # TODO: step 2. compute deltas on output layer (Hint: python index numbering starts from 0 ends at N-1)\n",
    "        # Correction in Instructions: From the instructions mentioned below for backward propagation,\n",
    "        # Use normal product instead of dot product in Step 2 and 6\n",
    "        # The derivative and gradient functions have already been implemented for you\n",
    "        # your code here\n",
    "        self.delta[-1] = self.grad_loss(self.a[-1], y) * self.g_prime(self.z[-1])\n",
    "        self.db[-1] = self.delta[-1]\n",
    "        self.dW[-1] = np.dot(self.delta[-1], self.a[-2].T)\n",
    "        \n",
    "        # TODO: step 3-6. loop backward through layers, backprop deltas, compute dWs and dbs\n",
    "        # your code here\n",
    "        for l in range(2, self.L):\n",
    "            self.delta[-l] = np.dot(self.W[-l+1].T, self.delta[-l+1]) * self.g_prime(self.z[-l])\n",
    "            self.db[-l] = self.delta[-l]\n",
    "            self.dW[-l] = np.dot(self.delta[-l], self.a[-l-1].T)\n",
    "            \n",
    "    def train(self, X_train, y_train, X_valid=None, y_valid=None,\n",
    "              eta=0.25, num_epochs=10, isPrint=True, isVis=False):\n",
    "        \"\"\"\n",
    "        Train the network with SGD \n",
    "        \n",
    "        :param X_train: matrix of training features \n",
    "        :param y_train: matrix of vector-encoded labels \n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize shuffled indices \n",
    "        shuffled_inds = list(range(X_train.shape[0]))\n",
    "        \n",
    "        # loop over training epochs (step 1.)\n",
    "        for ep in range(num_epochs):\n",
    "            \n",
    "            # shuffle indices \n",
    "            np.random.shuffle(shuffled_inds)\n",
    "            \n",
    "            # loop over training examples (step 2.) \n",
    "            for ind in shuffled_inds: \n",
    "                \n",
    "                # TODO: step 3. back prop to get derivatives \n",
    "                # your code here\n",
    "                self.back_prop(X_train[ind], y_train[ind])\n",
    "                \n",
    "                # TODO: step 4. update all weights and biases for all layers\n",
    "                # your code here\n",
    "                for l in range(1, self.L):\n",
    "                    self.W[l-1] -= eta * self.dW[l-1]\n",
    "                    self.b[l-1] -= eta * self.db[l-1]\n",
    "                \n",
    "            # print mean loss every 10 epochs if requested \n",
    "            if isPrint and (ep % 10) == 0:\n",
    "                print(\"epoch {:3d}/{:3d}: \".format(ep, num_epochs), end=\"\")\n",
    "                print(\"  train loss: {:8.3f}\".format(self.compute_loss(X_train, y_train)), end=\"\")\n",
    "                if X_valid is not None:\n",
    "                    print(\"  validation loss: {:8.3f}\".format(self.compute_loss(X_valid, y_valid)))\n",
    "                else:\n",
    "                    print(\"\")\n",
    "                    \n",
    "            if isVis and (ep % 20) == 0:\n",
    "                self.pretty_pictures(X_train, y_train, decision_boundary=True, epoch=ep)\n",
    "                    \n",
    "    def compute_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        compute average loss for given data set \n",
    "        \n",
    "        :param X: matrix of features \n",
    "        :param y: matrix of vector-encoded labels \n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        if len(X.shape) == 1:\n",
    "            X = X[np.newaxis, :]\n",
    "        if len(y.shape) == 1:\n",
    "            y = y[np.newaxis, :]\n",
    "        for x, t in zip(X, y):\n",
    "            self.forward_prop(x)\n",
    "            if len(t.shape) == 1:\n",
    "                t = t.reshape(-1, 1)\n",
    "            loss += 0.5 * np.sum((self.a[-1] - t) ** 2)\n",
    "        return loss / X.shape[0]\n",
    "    \n",
    "    \n",
    "    def gradient_check(self, x, y, h=1e-5):\n",
    "        \"\"\"\n",
    "        check whether the gradient is correct for X, y\n",
    "        \n",
    "        Assuming that back_prop has finished.\n",
    "        \"\"\"\n",
    "        for ll in range(self.L - 1):\n",
    "            oldW = self.W[ll].copy()\n",
    "            oldb = self.b[ll].copy()\n",
    "            for i in range(self.W[ll].shape[0]):\n",
    "                for j in range(self.W[ll].shape[1]):\n",
    "                    self.W[ll][i, j] = oldW[i, j] + h\n",
    "                    lxph = self.compute_loss(x, y)\n",
    "                    self.W[ll][i, j] = oldW[i, j] - h\n",
    "                    lxmh = self.compute_loss(x, y)\n",
    "                    grad = (lxph - lxmh) / (2 * h)\n",
    "                    assert abs(self.dW[ll][i, j] - grad) < 1e-5\n",
    "                    self.W[ll][i, j] = oldW[i, j]\n",
    "            for i in range(self.b[ll].shape[0]):\n",
    "                j = 0\n",
    "                self.b[ll][i, j] = oldb[i, j] + h\n",
    "                lxph = self.compute_loss(x, y)\n",
    "                self.b[ll][i, j] = oldb[i, j] - h\n",
    "                lxmh = self.compute_loss(x, y)\n",
    "                grad = (lxph - lxmh) / (2 * h)\n",
    "                assert abs(self.db[ll][i, j] - grad) < 1e-5\n",
    "                self.b[ll][i, j] = oldb[i, j]\n",
    "        \n",
    "            \n",
    "    def pretty_pictures(self, X, y, decision_boundary=False, epoch=None):\n",
    "        \"\"\"\n",
    "        Function to plot data and neural net decision boundary\n",
    "        \n",
    "        :param X: matrix of features \n",
    "        :param y: matrix of vector-encoded labels \n",
    "        :param decision_boundary: whether or not to plot decision \n",
    "        :param epoch: epoch number for printing \n",
    "        \"\"\"\n",
    "        \n",
    "        mycolors = {\"blue\": \"steelblue\", \"red\": \"#a76c6e\"}\n",
    "        colorlist = [c for (n,c) in mycolors.items()]\n",
    "        colors = [colorlist[np.argmax(yk)] for yk in y]\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "        \n",
    "        if decision_boundary:\n",
    "            xx, yy = np.meshgrid(np.linspace(-1.25,1.25,300), np.linspace(-1.25,1.25,300))\n",
    "            grid = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "            grid_pred = np.zeros_like(grid[:,0])\n",
    "            for ii in range(len(grid_pred)):\n",
    "                self.forward_prop(grid[ii,:])\n",
    "                grid_pred[ii] = np.argmax(self.a[-1])\n",
    "            grid_pred = grid_pred.reshape(xx.shape)\n",
    "            cmap = ListedColormap([\n",
    "                colorConverter.to_rgba('steelblue', alpha=0.30),\n",
    "                colorConverter.to_rgba('#a76c63', alpha=0.30)])\n",
    "            plt.contourf(xx, yy, grid_pred, cmap=cmap)\n",
    "            if epoch is not None: plt.text(-1.23,1.15, \"epoch = {:d}\".format(epoch), fontsize=16)\n",
    "\n",
    "        plt.scatter(X[:,0], X[:,1], color=colors, s=100, alpha=0.9)\n",
    "        plt.axis('off')\n",
    "        \n",
    "def generate_data(N, config=\"checkerboard\"):\n",
    "    X = np.zeros((N,2))\n",
    "    y = np.zeros((N,2)).astype(int)\n",
    "    \n",
    "    if config==\"checkerboard\":\n",
    "        nps, sqlen = N//9, 2/3\n",
    "        ctr = 0\n",
    "        for ii in range(3):\n",
    "            for jj in range(3):\n",
    "                X[ctr * nps : (ctr + 1) * nps, :] = np.column_stack(\n",
    "                    (np.random.uniform(ii * sqlen +.05-1, (ii+1) * sqlen - .05 -1, size=nps),\n",
    "                     np.random.uniform(jj * sqlen +.05-1, (jj+1) * sqlen - .05 -1, size=nps))) \n",
    "                y[ctr*nps:(ctr+1)*nps,(3*ii+jj)%2] = 1 \n",
    "                ctr += 1\n",
    "                \n",
    "    if config==\"blobs\":            \n",
    "        X, yflat = datasets.make_blobs(n_samples=N, centers=[[-.5,.5],[.5,-.5]],\n",
    "                                       cluster_std=[.20,.20],n_features=2)\n",
    "        for kk, yk in enumerate(yflat):\n",
    "            y[kk,:] = np.array([1,0]) if yk else np.array([0,1])\n",
    "            \n",
    "    \n",
    "    if config==\"circles\":\n",
    "        kk=0\n",
    "        while kk < N / 2:\n",
    "            sample = 2 * np.random.rand(2) - 1 \n",
    "            if np.linalg.norm(sample) <= .45:\n",
    "                X[kk,:] = sample \n",
    "                y[kk,:] = np.array([1,0])\n",
    "                kk += 1 \n",
    "        while kk < N:\n",
    "            sample = 2 * np.random.rand(2) - 1\n",
    "            dist = np.linalg.norm(sample)\n",
    "            if dist < 0.9 and dist > 0.55:\n",
    "                X[kk,:] = sample \n",
    "                y[kk,:] = np.array([0,1])\n",
    "                kk += 1\n",
    "                \n",
    "    if config==\"moons\":\n",
    "        X, yflat = datasets.make_moons(n_samples=N, noise=.05)\n",
    "        X[:,0] = .5 * (X[:,0] - .5)\n",
    "        X[:,1] = X[:,1] - .25\n",
    "        for kk, yk in enumerate(yflat):\n",
    "            y[kk, :] = np.array([1,0]) if yk else np.array([0,1])\n",
    "            \n",
    "    return X, y\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".MathJax nobr>span.math>span{border-left-width:0 !important};\n",
    "</style>\n",
    "\"\"\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba8a9062eafc5921b6f48f3059061aeb",
     "grade": false,
     "grade_id": "cell-a1169ae25f8d2180",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll be using our network to do binary classification of two-dimensional feature vectors.  Scroll down to the **Helper Functions** and examine the function ``generate_data``. Then mess around with the following cell to look at the various data sets available.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f92ff3db3fa8f79a60d8d3eb0ee9ae2",
     "grade": false,
     "grade_id": "cell-8796d2ab35301fb4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# play with this cell to look at the various data sets available\n",
    "# your code here\n",
    "\n",
    "nn = Network([2,3,2])\n",
    "X_train, y_train = generate_data(300, \"blobs\")\n",
    "nn.pretty_pictures(X_train, y_train, decision_boundary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee4fa946e983cf153374f13e101bc19c",
     "grade": false,
     "grade_id": "cell-ed7b994c9772a0dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    " Go up to the ``__init__`` function in the ``Network Class``.  How are we initializing a network?  What data structures are we using to store things like weights, biases, deltas, etc? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this implementation:\n",
    "\n",
    "- The forward_prop method initializes the activation of the input layer to x and then computes the activities (z) and activations (a) for each layer.\n",
    "- The back_prop method performs forward propagation, computes deltas on the output layer, and then backpropagates deltas to compute derivatives of weights (dW) and biases (db).\n",
    "-  The train method shuffles the training examples, performs backpropagation to get derivatives, and updates weights and biases using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "666fca44a1dc9fc1c5fab95c203e5ca8",
     "grade": false,
     "grade_id": "cell-fdb21fabf399efc7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART A.** Implementing Forward Propagation. \n",
    "\n",
    "Complete the ``forward_prop`` function to implement forward propagation.  Your function should take in a single training example ``x`` and propagate it forward in the network, setting the activations and activities on the hidden and output layers.  Remember that the pseudocode that we wrote for forward-prop looked as follows: \n",
    "\n",
    "1. $\\quad$Initialize ${\\bf a}^0 = {\\bf x}$\n",
    "2. $\\quad$For $\\ell = 0, \\ldots, L-1$: \n",
    "3. $\\quad\\quad\\quad{\\bf z}^{\\ell+1} = W^\\ell {\\bf a}^\\ell + {\\bf b}^\\ell$\n",
    "3. $\\quad\\quad\\quad{\\bf a}^{\\ell+1} = g({\\bf z}^{\\ell+1})$\n",
    "\n",
    "When you think you're done, we can instantiate a ``Network`` with with $2$ neurons in the input layer, $3$ neurons in the sole hidden layer, and $2$ neurons in the output layer, and then forward prop one of the training examples. \n",
    "\n",
    "Check that your indexing was correct by making sure that all of the activations are now non-zero (remember, we initialized them to vectors of zeros). \n",
    "\n",
    "What other things could we check?<br>\n",
    "Answer the question about this section in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "683d64e7490b34adc182caf546dd13cd",
     "grade": false,
     "grade_id": "cell-767905ab9692f8e4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.],\n",
       "        [0.]]),\n",
       " array([[-0.02839653],\n",
       "        [ 1.37809345],\n",
       "        [-0.72694316]]),\n",
       " array([[-0.82925159],\n",
       "        [ 0.6198315 ]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test your forward_prop function\n",
    "nn = Network([2,3,2])\n",
    "nn.forward_prop(X_train[0])\n",
    "nn.z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cabf84e7a646a18fd7f853eef92e75c6",
     "grade": false,
     "grade_id": "cell-ecb5d896a0389f91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART B.** Implementing Back Propagation\n",
    "\n",
    "OK, now it's time to implement back propagation.  Complete the function ``back_prop`` in the ``Network`` class to use a single training example to compute the derivatives of the loss function with respect to the weights and the biases.  Remember, the pseudocode for back-prop was as follows: \n",
    "\n",
    "1. $\\quad$Forward propagate the training example ${\\bf x}$, ${\\bf y}$\n",
    "2. $\\quad$Compute the $\\delta^L = \\dfrac{\\partial \\mathscr{L}}{\\partial {\\bf a}^L} \\odot g'({\\bf z}^L)$\n",
    "3. $\\quad$For $\\ell = L-1, \\ldots, 1$: \n",
    "4. $\\quad\\quad\\quad \\dfrac{\\partial \\mathscr{L}}{\\partial W^\\ell} = \\delta^{\\ell+1} ({\\bf a}^\\ell)^T$\n",
    "5. $\\quad\\quad\\quad \\dfrac{\\partial \\mathscr{L}}{\\partial {\\bf b}^\\ell} = \\delta^{\\ell+1}$\n",
    "6. $\\quad\\quad\\quad\\delta^{\\ell} = (W^\\ell)^T\\delta^{\\ell+1} \\odot g'({\\bf z}^\\ell)$\n",
    "\n",
    "When you think you're done, instantiate a small ``Network`` and call back-prop for a single training example.  \n",
    "\n",
    "Check that it's likely working by checking that the derivative matrices ``dW`` and ``db`` are nonzero. <br>\n",
    "Answer the question about this section in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08922f1b4829b160fb0036b65055f045",
     "grade": false,
     "grade_id": "cell-450534d4eefea854",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15851682 -0.06779632]\n",
      " [-0.61924852 -2.13350613]\n",
      " [-0.3415946   0.19783002]]\n"
     ]
    }
   ],
   "source": [
    "# test back_prop\n",
    "nn = Network([2,3,2])\n",
    "nn.back_prop(X_train[0,:], y_train[0,:])\n",
    "print(nn.W[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee835c3287997068112220b2c1940138",
     "grade": false,
     "grade_id": "cell-f9d911032fb2aa10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15851682 -0.06779632]\n",
      " [-0.61924852 -2.13350613]\n",
      " [-0.3415946   0.19783002]]\n"
     ]
    }
   ],
   "source": [
    "# test gradient_check \n",
    "nn.gradient_check(X_train[0, :], y_train[0, :])\n",
    "print(nn.W[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e6e786621257104cf6c282bd74880da9",
     "grade": false,
     "grade_id": "cell-0b14a3db8cca78bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The below test cells are to help you validate your forward and backward propagation functions better and help you identify problem areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cf6f7175086d717700c7b37d88f9d29",
     "grade": true,
     "grade_id": "cell-87b6b4d4b5259351",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network Tests - Forward Propagation\n",
    "# PLEASE NOTE: These sample tests are only indicative and are added to help you debug your code\n",
    "\n",
    "mock_X = np.array([[-0.4838731, 0.08083195], [0.93456167, -0.50316134]])\n",
    "np.random.seed(42)  ## DO NOT CHANGE THE SEED VALUE HERE\n",
    "nn1 = Network([2,3,2])\n",
    "nn1.forward_prop(mock_X)                 \n",
    "                 \n",
    "a = np.array([[0.],[0.]])\n",
    "b = np.array([[ 2.08587849, -0.31681043],[-0.94835809,  0.15999031],[-0.04793409,  0.92471859]])\n",
    "c = np.array([[ 0.24259536,  0.0874714 ],[-2.41978734, -1.98990137]])\n",
    "forward_z = [a, b, c]\n",
    "\n",
    "for pred, true in zip(nn1.z, forward_z):\n",
    "    assert pytest.approx(pred, 0.01) == true, \"Check forward function\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56706f8d80cb38659f089c8bb09d8133",
     "grade": true,
     "grade_id": "cell-ad565ceb6c1c4f33",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Neural Network Tests - Backward Propagation\n",
    "# PLEASE NOTE: These sample tests are only indicative and are added to help you debug your code\n",
    "\n",
    "mock_y = 0 * mock_X + 1\n",
    "np.random.seed(42)  ## DO NOT CHANGE THE SEED VALUE HERE\n",
    "nn1.back_prop(mock_X, mock_y)\n",
    "\n",
    "backward_w = [[-0.23413696, 1.57921282], [ 0.76743473, -0.46947439], [ 0.54256004, -0.46341769]]\n",
    "\n",
    "pred = nn1.W[0]\n",
    "true = backward_w\n",
    "\n",
    "assert pytest.approx(pred, 0.01) == true, \"Check backward function\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b92441196065ee6db7f3fd50a46198b5",
     "grade": false,
     "grade_id": "cell-f88c764886880cb8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note:** Next week, we will cover stochastic gradient descent. We encourage you to complete the following sections to train your model and get some results if you know how to do so. These sections are ungraded, so don't feel pressure to skip ahead a week in the material. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ce87a683078141d792388d816a283df",
     "grade": false,
     "grade_id": "cell-0466786367631c1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART C. [Ungraded]** Implementing trainning using stochastic gradient descent \n",
    "\n",
    "OK, now let's actually train a neural net!  Complete the missing code in ``train`` to loop over the training data in random order, call back-prop to get the derivatives, and then update the weights and the biases via SGD. SGD uses minibatch to update weights. The training algorithm is following.\n",
    "1. For epoch = 0,1,...,N:\n",
    "2.     For (Xbatch, ybatch) in minibatches:\n",
    "3.         Compute gradients using backpropagation for the minibatch data\n",
    "4.         Update the weights (W, b) in the all layers (use loop over layer)    \n",
    "\n",
    "When you think you're done, execute the following code and watch the training loss evolve over the training process.  If you've done everything correctly, it'll hopefully go down! <br><br>\n",
    "Check out the solution in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9062636f24110251b8f4bf7701b5907b",
     "grade": false,
     "grade_id": "cell-8d3e9ba04e6d283c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**PART D.[Ungraded]**     \n",
    "OK! If you think you've worked out the bugs, let's start looking at the results. We'll build a simple neural network, train it on a training set, and watch the decision boundary of our classifier evolve to fit the data. We can do this by running similar code as above, but with the isVis flag set to True. Note that producing the plots takes considerable computational work, so things will go a bit slower now.\n",
    "\n",
    "Start with the blobs data set, and then move on to more complicated data sets like moons, circles, and finally the checkerboard. Note that for these more complicated geometries, it'll probably be necessary to chain the number of neurons in your hidden layer, or even add more hidden layers! <br>\n",
    "Check out the solution in this week's Peer Review assignment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
