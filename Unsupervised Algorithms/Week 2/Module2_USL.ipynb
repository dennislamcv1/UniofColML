{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "556d9673a40cef731438819650b4afeb",
     "grade": false,
     "grade_id": "cell-3fab386f48bbd974",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Grading\n",
    "This week's lab doesn't have any auto-graded components. Each question in this notebook has an accompanying Peer Review question. Although the lab shows as being ungraded, you need to complete the notebook to answer the Peer Review questions. <br>\n",
    "**DO NOT CHANGE VARIABLE OR METHOD SIGNATURES** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19ae55b356f0ad3dfda48f3cb99dddb9",
     "grade": false,
     "grade_id": "cell-9488ace019b4c835",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Validate Button\n",
    "This week's lab doesn't have any auto-graded components. Each question in this notebook has an accompanying Peer Review question. Although the lab shows as being ungraded, you need to complete the notebook to answer the Peer Review questions. \n",
    "\n",
    "You do not need to use the Validate button for this lab since there are no auto-graded components. If you hit the Validate button, it will time out given the number of visualizations in the notebook. Cells with longer execution times cause the validate button to time out and freeze. ***This notebook's Validate button time-out does not affect the final submission grading.*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "local-marketing",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "412c0fbff4d9e5401141ed5f953ba132",
     "grade": false,
     "grade_id": "cell-539bfe3db5c0f774",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Clustering RNA sequences to identify cancer types\n",
    "\n",
    "In this assignment, we will use clustering algorithms on RNA sequence data to identify cancer types.\n",
    "Since the [whole data](https://www.synapse.org/#!Synapse:syn4301332) (from [Cancer Genome Atlas Pan-Cancer project](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3919969/)) is very big, we will use a [subset data from UCI Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/gene+expression+cancer+RNA-Seq#). The subset data contains only 5 labels; BRCA, KIRC, COAD, LUAD and PRAD. The meanings of those labels are as below.\n",
    "\n",
    "|Abbreviation|Cancer|\n",
    "|:----:|:-------:|\n",
    "|LUSC|Lung squamous cell carcinoma |\n",
    "|READ |Rectum adenocarcinoma |\n",
    "|GBM |Glioblastoma multiforme|\n",
    "|BLCA |Bladder Urothelial Carcinoma|\n",
    "|UCEC |Uterine Corpus Endometrioid Carcinoma|\n",
    "|COAD |Colon adenocarcinoma|\n",
    "|OV |Ovarian serous cystadenocarcinoma|\n",
    "|LAML |Acute Myeloid Leukemia|\n",
    "|HNSC |Head and Neck squamous cell carcinoma|\n",
    "|LUAD |Lung adenocarcinoma|\n",
    "|BRCA |Breast invasive carcinoma|\n",
    "|KIRC |Kidney renal clear cell carcinoma|\n",
    "\n",
    "Although we can use the data for supervised learning model training, we will not use these labels for training, but use them for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ordered-pasta",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "deb30e3992bd6264bc0999a631f4f249",
     "grade": false,
     "grade_id": "cell-aae50706a878da7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "forbidden-patrol",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d54524a953add3d7536b6f813e910b6",
     "grade": false,
     "grade_id": "cell-0349e5e5a7302cd2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Read data. Do not change the variable names (data, label)\n",
    "data = pd.read_csv('data/data.csv')\n",
    "label = pd.read_csv('data/labels.csv')\n",
    "data=data.drop('Unnamed: 0',axis=1)\n",
    "label=label.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "universal-consultancy",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70fad3bc72f0de4ef37faa39dbc1aca1",
     "grade": false,
     "grade_id": "cell-a2791930798cf4eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### A. [Peer Review] Perform basic data inspection or EDA on the pandas dataframe.\n",
    "- How many observations?\n",
    "- How many features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b9a724c90825ae8d7bc9a7d59a37620",
     "grade": false,
     "grade_id": "cell-2958c08df1714546",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 801 entries, 0 to 800\n",
      "Columns: 20531 entries, gene_0 to gene_20530\n",
      "dtypes: float64(20531)\n",
      "memory usage: 125.5 MB\n",
      "None\n",
      "\n",
      "Data Head:\n",
      "   gene_0    gene_1    gene_2    gene_3     gene_4  gene_5    gene_6  \\\n",
      "0     0.0  2.017209  3.265527  5.478487  10.431999     0.0  7.175175   \n",
      "1     0.0  0.592732  1.588421  7.586157   9.623011     0.0  6.816049   \n",
      "2     0.0  3.511759  4.327199  6.881787   9.870730     0.0  6.972130   \n",
      "3     0.0  3.663618  4.507649  6.659068  10.196184     0.0  7.843375   \n",
      "4     0.0  2.655741  2.821547  6.539454   9.738265     0.0  6.566967   \n",
      "\n",
      "     gene_7  gene_8  gene_9  ...  gene_20521  gene_20522  gene_20523  \\\n",
      "0  0.591871     0.0     0.0  ...    4.926711    8.210257    9.723516   \n",
      "1  0.000000     0.0     0.0  ...    4.593372    7.323865    9.740931   \n",
      "2  0.452595     0.0     0.0  ...    5.125213    8.127123   10.908640   \n",
      "3  0.434882     0.0     0.0  ...    6.076566    8.792959   10.141520   \n",
      "4  0.360982     0.0     0.0  ...    5.996032    8.891425   10.373790   \n",
      "\n",
      "   gene_20524  gene_20525  gene_20526  gene_20527  gene_20528  gene_20529  \\\n",
      "0    7.220030    9.119813   12.003135    9.650743    8.921326    5.286759   \n",
      "1    6.256586    8.381612   12.674552   10.517059    9.397854    2.094168   \n",
      "2    5.401607    9.911597    9.045255    9.788359   10.090470    1.683023   \n",
      "3    8.942805    9.601208   11.392682    9.694814    9.684365    3.292001   \n",
      "4    7.181162    9.846910   11.922439    9.217749    9.461191    5.110372   \n",
      "\n",
      "   gene_20530  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "3         0.0  \n",
      "4         0.0  \n",
      "\n",
      "[5 rows x 20531 columns]\n",
      "\n",
      "Label Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 801 entries, 0 to 800\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Class   801 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 6.4+ KB\n",
      "None\n",
      "\n",
      "Label Head:\n",
      "  Class\n",
      "0  PRAD\n",
      "1  LUAD\n",
      "2  PRAD\n",
      "3  PRAD\n",
      "4  BRCA\n",
      "\n",
      "Number of observations: 801\n",
      "Number of features: 20531\n"
     ]
    }
   ],
   "source": [
    "# perform basic data inspection such as getting the number of observations and number of features\n",
    "# you can also display part of the dataframe or run data.info() \n",
    "# your code here\n",
    "# Perform basic data inspection\n",
    "# Display part of the dataframe and run data.info()\n",
    "print(\"Data Information:\")\n",
    "print(data.info())\n",
    "print(\"\\nData Head:\")\n",
    "print(data.head())\n",
    "\n",
    "print(\"\\nLabel Information:\")\n",
    "print(label.info())\n",
    "print(\"\\nLabel Head:\")\n",
    "print(label.head())\n",
    "\n",
    "# Number of observations and features\n",
    "num_observations = data.shape[0]\n",
    "num_features = data.shape[1]\n",
    "\n",
    "print(f\"\\nNumber of observations: {num_observations}\")\n",
    "print(f\"Number of features: {num_features}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "65492cc771478d0c9c26f1a73857843a",
     "grade": false,
     "grade_id": "cell-bde1524da0e9a63f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- Draw histograms of mean, max and min values in each feature. You may see numbers around 0-20. What do those numbers mean? (We do not expect students to know or figure out the meanings, but if you do know by chance, feel free to discuss them with the class on the discussion board.) <br>\n",
    "Answer the Peer Review question about this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4abf73a9c24337560f0e0557bb0f7df",
     "grade": false,
     "grade_id": "cell-dcce43bb9bf942c0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw histograms of mean, max and min values in each feature \n",
    "# your code here\n",
    "# Calculate mean, max, and min values for each feature\n",
    "feature_means = data.mean(axis=0)\n",
    "feature_max = data.max(axis=0)\n",
    "feature_min = data.min(axis=0)\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(feature_means, bins=50, color='blue', alpha=0.7)\n",
    "plt.title('Histogram of Feature Means')\n",
    "plt.xlabel('Mean')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(feature_max, bins=50, color='green', alpha=0.7)\n",
    "plt.title('Histogram of Feature Max Values')\n",
    "plt.xlabel('Max')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(feature_min, bins=50, color='red', alpha=0.7)\n",
    "plt.title('Histogram of Feature Min Values')\n",
    "plt.xlabel('Min')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f10e915af8708dc8de4c6a2a8ca51108",
     "grade": false,
     "grade_id": "cell-6736f47726a243e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "- If we were to train a \"supervised\" learning model, how would you deal with such large feature dimension? \n",
    "- Even after feature dimension reduction, still the number of useful features may be enormous. How it would impact performance or runtime of certain supervised learning algorithms? Which algorithms would suffer from high dimension features than others and why? \n",
    "- How it would impact performance or runtime of an unsupervised learning algorithm?\n",
    "- Draw histograms of mean, max and min values in each feature. You may see numbers around 0-20. What those numbers mean? (We do not expect students to know or figure out the meanings, but if you do know by chance, feel free to discuss them with the class on the discussion board.) <br> <br>\n",
    "Anwer these questions in this week's Peer Review assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Discussion and Analysis\n",
    "\n",
    "#### 1. Supervised Learning and High Dimensional Data\n",
    "\n",
    "**How to Deal with Large Feature Dimension:**\n",
    "- **Dimensionality Reduction:** Techniques such as PCA (Principal Component Analysis) or LDA (Linear Discriminant Analysis) can be used to reduce the feature dimensions while retaining most of the variance or discriminative information.\n",
    "- **Feature Selection:** Methods such as mutual information, correlation analysis, and various statistical tests can help in selecting the most relevant features.\n",
    "\n",
    "**Impact on Performance and Runtime:**\n",
    "- **High Dimensionality Impact:** High-dimensional data can lead to the \"curse of dimensionality,\" which can negatively affect the performance of supervised learning models. It increases the computational cost and can cause overfitting.\n",
    "- **Algorithms Affected:**\n",
    "  - **Decision Trees and Random Forests:** May suffer from overfitting and increased computational cost due to high dimensionality.\n",
    "  - **K-Nearest Neighbors (KNN):** Performance degrades as the number of dimensions increases because distance calculations become less meaningful in high-dimensional spaces.\n",
    "  - **Linear Models (e.g., Logistic Regression, SVM):** May perform better with proper regularization but can still suffer from increased computational cost.\n",
    "\n",
    "#### 2. Unsupervised Learning and High Dimensional Data\n",
    "\n",
    "**Impact on Performance and Runtime:**\n",
    "- **Agglomerative Clustering:** May suffer from increased computational cost as it involves calculating distances between all pairs of points.\n",
    "- **K-Means Clustering:** High-dimensional data can lead to less meaningful cluster centroids, making it harder for the algorithm to converge to a meaningful solution.\n",
    "\n",
    "### Histograms of Feature Values\n",
    "\n",
    "**Interpretation of Feature Values:**\n",
    "- The feature values being around 0-20 likely indicate normalized or scaled data. These values might represent gene expression levels which are often transformed for analysis purposes.\n",
    "\n",
    "The exact biological or clinical significance of these values would depend on the context of the specific RNA sequences and cancer types. However, for our analysis, understanding the statistical distribution is more pertinent for preprocessing and model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36d2fc3f5b54ad32960f5d4ae52f2100",
     "grade": false,
     "grade_id": "cell-f89786ce6c22a413",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### B. [Peer Review] Build a hierarchical clustering model\n",
    "Let's build a model using hierarchical clustering. Hierarchical clustering module is available from `sklearn.cluster.AgglomerativeClustering`. You can choose linkage type and metric. Please check its documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "944b291a4ed47f6acd91034c448514b9",
     "grade": false,
     "grade_id": "cell-20bd5000b96709cd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**a) Number of clusters vs distance threshold**\n",
    "Oftentimes hierarchical clustering does not need to know the number of clusters in advance. Instead, one needs to choose threshold distance/similarity to cut the dendrogram later. The AgglomerativeClustering module lets you specify either the number of clusters (n_clusters) or the threshold (distance_threshold). Based on our data, which should we choose to set to which value and why? <br> <br>\n",
    "Answer this question in the Peer Review assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "479da534d14157edc6cab3a8c6dce4b6",
     "grade": false,
     "grade_id": "cell-1dcb3a4ab605373a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### b) Guess which metric?\n",
    "Can you guess which metric to use (distance-based vs. similarity-based) and why? \n",
    "This question is not graded, but we encourage you to share your thoughts with the class. See the ungraded discussion prompt for this week's material. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e2681cdcd943f508b334d717be6461f4",
     "grade": false,
     "grade_id": "cell-3bdcbf312ff9cbef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### c) Build a model\n",
    "Build a model using n_clusters=5 option. Choose any metric and linkage type at first. Display the clustering result labels (you can just print out the result). Do not change the variable (model) name. Answer the question about this section in the Peer Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a026cf9b5831deeb187d3b6279c2cbd",
     "grade": false,
     "grade_id": "cell-a182891914c1787d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering Result Labels:\n",
      "[2 3 2 2 0 2 1 2 0 2 0 1 2 0 0 0 3 1 1 2 0 1 3 0 1 3 4 0 0 0 0 0 1 0 2 0 1\n",
      " 3 0 0 1 2 2 1 1 0 2 4 0 3 0 3 0 2 4 0 0 4 1 0 3 1 0 3 2 4 0 2 1 0 1 0 0 3\n",
      " 0 3 0 1 2 4 0 2 0 0 2 2 0 0 1 0 2 2 0 0 0 2 4 0 2 0 0 1 0 1 3 1 3 4 3 3 2\n",
      " 0 3 2 0 1 1 1 0 0 3 1 3 0 2 2 2 0 1 0 4 0 4 0 0 1 3 0 1 4 0 2 0 1 3 4 2 0\n",
      " 3 3 3 3 0 0 3 0 0 2 2 3 2 3 1 0 2 3 4 1 3 0 1 3 0 3 0 0 0 2 0 1 4 1 0 2 2\n",
      " 2 3 3 0 3 3 1 3 2 3 0 0 0 3 3 0 1 1 1 1 2 0 2 0 3 3 0 2 0 2 0 0 0 3 0 1 3\n",
      " 1 1 3 0 1 2 0 3 3 2 4 0 1 2 1 4 0 1 1 3 2 2 3 3 1 0 0 4 0 2 4 0 2 1 2 2 2\n",
      " 0 4 4 3 4 4 2 3 0 0 1 1 0 4 2 1 2 0 0 1 0 0 0 0 3 3 0 0 0 1 1 1 1 0 0 0 1\n",
      " 0 0 3 2 0 0 4 3 2 0 0 0 4 0 2 0 4 3 3 2 1 0 1 1 3 4 1 0 0 0 0 1 0 0 2 0 1\n",
      " 0 3 2 1 0 2 4 0 0 0 3 3 3 0 0 2 3 0 1 0 4 4 3 0 1 0 0 0 4 3 4 1 2 1 0 0 1\n",
      " 0 4 2 3 2 0 1 2 0 4 1 1 4 4 2 0 0 4 1 3 2 0 0 0 3 3 1 3 0 1 4 2 0 3 2 0 0\n",
      " 0 3 0 0 2 0 2 4 0 3 0 0 3 0 0 0 1 3 2 0 2 1 0 1 4 0 2 3 1 0 0 1 0 3 0 0 2\n",
      " 4 0 1 3 2 0 2 0 0 0 0 1 3 0 1 0 0 3 3 1 4 2 4 0 1 1 0 2 1 4 3 3 0 2 2 0 2\n",
      " 3 1 2 0 3 2 3 0 0 4 3 1 4 3 0 2 0 0 2 0 4 0 4 1 0 0 3 3 3 4 1 3 3 0 0 1 2\n",
      " 3 2 0 1 0 1 1 2 2 3 0 1 4 4 0 1 1 0 0 2 1 4 0 0 4 3 0 0 0 1 2 3 3 0 1 4 1\n",
      " 1 0 2 3 1 0 4 3 3 3 2 3 1 0 0 4 2 0 0 0 1 3 3 0 2 3 3 0 1 2 4 3 2 4 3 4 1\n",
      " 1 0 0 1 1 4 0 0 2 2 1 0 3 0 0 4 0 2 2 0 0 4 0 1 0 0 4 0 2 0 0 1 2 3 0 0 1\n",
      " 0 0 0 0 0 4 3 3 0 0 0 2 0 0 1 3 3 1 1 3 1 4 0 4 1 0 0 2 2 2 3 2 2 4 0 0 4\n",
      " 3 1 0 1 4 0 0 0 2 3 1 0 2 1 2 0 3 1 2 3 2 2 0 1 2 3 4 4 0 0 0 3 1 1 1 0 3\n",
      " 1 2 0 3 2 0 2 0 1 0 4 2 2 1 2 1 0 3 3 0 0 1 0 0 0 0 1 1 2 4 1 0 0 1 0 3 0\n",
      " 0 2 0 2 0 4 0 0 1 3 0 0 2 0 2 4 0 0 0 3 0 3 0 3 1 1 4 4 0 0 0 3 0 3 1 0 3\n",
      " 1 3 3 3 1 0 2 0 0 1 0 2 1 0 0 0 0 2 3 0 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "# build a model using n_clusters=5 option\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Build the Agglomerative Clustering model\n",
    "model = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward')\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(data)\n",
    "\n",
    "# Display the clustering result labels\n",
    "labels = model.labels_\n",
    "print(\"Clustering Result Labels:\")\n",
    "print(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Number of Clusters vs Distance Threshold\n",
    "We chose to set `n_clusters=5` instead of using `distance_threshold` because:\n",
    "1. The dataset has known labels for evaluation.\n",
    "2. It ensures our clustering output can be directly compared to the known cancer types, facilitating evaluation of the modelâ€™s performance.\n",
    "\n",
    "#### b) Guess Which Metric?\n",
    "A distance-based metric such as Euclidean distance is appropriate for this dataset because it measures the straight-line distance between data points in the feature space, which aligns well with how RNA sequence data (gene expression levels) are typically analyzed.\n",
    "\n",
    "#### c) Model Building\n",
    "We used `AgglomerativeClustering` with `n_clusters=5`, `affinity='euclidean'`, and `linkage='ward'`. The clustering result labels were printed to the console. \n",
    "\n",
    "Feel free to run the provided code to fit the model and observe the clustering results. You can then compare these labels to the actual cancer type labels to evaluate the performance of the clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa88212d918a8521a87412958a95f3ef",
     "grade": false,
     "grade_id": "cell-14da739b5647db81",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### d) Label permuation\n",
    "In clustering, the labels get assigned randomly, so the label numbering won't match the ground truth necessarily. Write a function below to find best matching label ordering based on the accuracy. Do not change the variable names. Answer the question about this section in the Peer Review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f47665d2983a53c6a92c098e5070fc63",
     "grade": false,
     "grade_id": "cell-82b20e00978bc5e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def label_permute_compare(ytdf, yp, n=5):\n",
    "    \"\"\"\n",
    "    ytdf: labels dataframe object\n",
    "    yp: clustering label prediction output\n",
    "    Returns permuted label order and accuracy. \n",
    "    Example output: (3, 4, 1, 2, 0), 0.74 \n",
    "    \"\"\"\n",
    "    ### BEGIN SOLUTION    \n",
    "    perms = list(itertools.permutations(list(range(n))))\n",
    "    acc=[]\n",
    "    for i in range(len(perms)):\n",
    "        mapdict = dict(zip(list(label['Class'].unique()),list(perms[i])))\n",
    "        yt = ytdf['Class'].apply(lambda x: mapdict[x])\n",
    "        acc.append(accuracy_score(yt,yp))\n",
    "    idx = np.argmax(acc)    \n",
    "    return perms[idx], acc[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf8892a7991eab729501b9f12fa11ae1",
     "grade": false,
     "grade_id": "cell-e59b3dddfdc36871",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 0, 1, 4) 0.9950062421972534\n"
     ]
    }
   ],
   "source": [
    "labelorder, acc = label_permute_compare(label, model.labels_)\n",
    "print(labelorder, acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "246f7bd7bd4cacc06d3d8e7b0811e06b",
     "grade": false,
     "grade_id": "cell-2dee0f590af15ca1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### e) Check confusion matrix\n",
    "Use sklearn's confusion matrix and display the results. Answer the Peer Review question about this section.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7db659d69e66d44725a24b1f90796541",
     "grade": false,
     "grade_id": "cell-b7fe98331f7b544f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-11e16b273982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermuted_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Plot the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "# display confusion matrix here \n",
    "# your code here\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply the best permutation to the predicted labels\n",
    "permuted_labels = [labelorder[label] for label in model.labels_]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(label, permuted_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(label), yticklabels=np.unique(label))\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49b995d1748051a814f09ae8878096cd",
     "grade": false,
     "grade_id": "cell-b51181ebab84b037",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### f) Change linkage method and distance metric. Which ones lead the best performance? Print out the accuracy and confusion matrix for the best model.\n",
    "<br> Answer the Peer Review questions about this section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a13e0521cb941ebbe96ef06b0f48bf8c",
     "grade": false,
     "grade_id": "cell-03953f78e5852c9a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.515841007232666 ward euclidean (2, 3, 0, 1, 4) 0.9950062421972534\n",
      "ward with l1 not allowed.\n",
      "ward with l2 not allowed.\n",
      "ward with manhattan not allowed.\n",
      "ward with cosine not allowed.\n",
      "6.499619007110596 complete euclidean (4, 3, 1, 0, 2) 0.9313358302122348\n",
      "6.501010417938232 complete l1 (4, 3, 0, 1, 2) 0.7228464419475655\n",
      "6.495062828063965 complete l2 (4, 3, 1, 0, 2) 0.9313358302122348\n",
      "6.529598712921143 complete manhattan (4, 3, 0, 1, 2) 0.7228464419475655\n",
      "6.370205879211426 complete cosine (3, 4, 1, 2, 0) 0.7403245942571786\n",
      "6.635839462280273 average euclidean (2, 4, 0, 3, 1) 0.3645443196004994\n",
      "6.608386516571045 average l1 (1, 2, 0, 3, 4) 0.365792759051186\n",
      "6.614640474319458 average l2 (2, 4, 0, 3, 1) 0.3645443196004994\n",
      "6.5921173095703125 average manhattan (1, 2, 0, 3, 4) 0.365792759051186\n",
      "6.4065024852752686 average cosine (2, 4, 1, 3, 0) 0.3645443196004994\n",
      "6.678339958190918 single euclidean (1, 2, 0, 3, 4) 0.3757802746566791\n",
      "6.591625928878784 single l1 (3, 1, 0, 2, 4) 0.37453183520599254\n",
      "6.600521802902222 single l2 (1, 2, 0, 3, 4) 0.3757802746566791\n",
      "6.5289306640625 single manhattan (3, 1, 0, 2, 4) 0.37453183520599254\n",
      "6.314710855484009 single cosine (1, 2, 0, 3, 4) 0.3757802746566791\n",
      "0.9950062421972534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[299,   0,   0,   1,   0],\n",
       "       [  0, 146,   0,   0,   0],\n",
       "       [  0,   0, 136,   0,   0],\n",
       "       [  2,   0,   0, 139,   0],\n",
       "       [  0,   0,   0,   1,  77]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# programmatically evaluate which linkage method and distance metric lead to the best performance\n",
    "# your code here\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for linkage in ['ward', 'complete', 'average', 'single']:\n",
    "    for affinity in ['euclidean', 'l1', 'l2', 'manhattan', 'cosine']:\n",
    "        acc=0\n",
    "        t0=time.time()\n",
    "        try:\n",
    "            model = AgglomerativeClustering(n_clusters=5,linkage=linkage,affinity=affinity).fit(data)\n",
    "            labelorder, acc = label_permute_compare(label,model.labels_)   \n",
    "            t1=time.time()\n",
    "            print(t1-t0, linkage, affinity, labelorder, acc)    \n",
    "        except:    \n",
    "            print(linkage, 'with', affinity, 'not allowed.')\n",
    "            \n",
    "# Final answer            \n",
    "model = AgglomerativeClustering(n_clusters=5,linkage='ward',affinity='euclidean').fit(data)  \n",
    "labelorder, acc = label_permute_compare(label,model.labels_)   \n",
    "mapdict = dict(zip(list(label['Class'].unique()),list(labelorder)))\n",
    "yt = label['Class'].apply(lambda x: mapdict[x])\n",
    "print(acc)\n",
    "confusion_matrix(yt,model.labels_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9eeef63c833a862a824bd957b4569d81",
     "grade": false,
     "grade_id": "cell-6cd5993178e6f606",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### C. What about k-means clustering?\n",
    "Can we apply kmeans clustering on this data? Which clustering methods give a better performance? Is kmeans faster or slower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff50d6cc5b9fbf0fface11dad35bfaba",
     "grade": false,
     "grade_id": "cell-2f77201b65ef6a7a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.32960820198059\n",
      "(0, 3, 1, 2, 4) 0.9937578027465668\n",
      "0.9937578027465668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[136,   0,   0,   0,   0],\n",
       "       [  0, 300,   0,   0,   0],\n",
       "       [  0,   1, 145,   0,   0],\n",
       "       [  0,   2,   0, 139,   0],\n",
       "       [  0,   0,   0,   2,  76]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to apply kmeans clustering on this data\n",
    "# time kmeans to compare to hierarchical clustering \n",
    "# your code here\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "\n",
    "t0=time.time()\n",
    "kmeans = KMeans(5).fit(data)\n",
    "t1=time.time()\n",
    "print(t1-t0)\n",
    "labelorder, acc = label_permute_compare(label,kmeans.labels_)\n",
    "print(labelorder, acc)\n",
    "mapdict = dict(zip(list(label['Class'].unique()),list(labelorder)))\n",
    "yt = label['Class'].apply(lambda x: mapdict[x])\n",
    "print(acc)\n",
    "confusion_matrix(yt,kmeans.labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "HW2-clustering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
